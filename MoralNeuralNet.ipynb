{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoralNeuralNet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMdCH9T0y2LN4TLcGl7KZgU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t0brig01/CSE696FinalProject/blob/main/MoralNeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zrLBI6pAHL1",
        "outputId": "32889ad2-b1c2-475f-b5d2-2b3c96a40bf4"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from pandas import concat\r\n",
        "from sklearn import preprocessing\r\n",
        "print (\"TensorFlow version: \" + tf.__version__)\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from sklearn.pipeline import Pipeline\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import StratifiedKFold\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from imblearn.over_sampling import SMOTE as smt\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "TensorFlow version: 1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZVH15Vu1R88"
      },
      "source": [
        "# **Data Loading/Manipulation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yfK1H0OvFez"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/t0brig01/CSE696FinalProject/main/TrolleyData.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZjiIHOveFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1496fde2-99e8-42a7-f88c-c1bdd271aa75"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 230475 entries, 0 to 230474\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   _id             230475 non-null  object\n",
            " 1   Scenario        230475 non-null  object\n",
            " 2   UserID          230475 non-null  object\n",
            " 3   Outcome         230475 non-null  int64 \n",
            " 4   Session_id      230475 non-null  object\n",
            " 5   Scenario_order  230475 non-null  int64 \n",
            " 6   Template        230475 non-null  object\n",
            " 7   answerLeft      230475 non-null  bool  \n",
            " 8   lang            230475 non-null  object\n",
            " 9   seenOther       230475 non-null  bool  \n",
            " 10  country_code    229259 non-null  object\n",
            " 11  country_full    229259 non-null  object\n",
            "dtypes: bool(2), int64(2), object(8)\n",
            "memory usage: 18.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WgRLKBDvfEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6f50d238-d003-4d5f-a17e-c16170874334"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>Scenario</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Session_id</th>\n",
              "      <th>Scenario_order</th>\n",
              "      <th>Template</th>\n",
              "      <th>answerLeft</th>\n",
              "      <th>lang</th>\n",
              "      <th>seenOther</th>\n",
              "      <th>country_code</th>\n",
              "      <th>country_full</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C3RGCjGPftjMKYHy2</td>\n",
              "      <td>Loop</td>\n",
              "      <td>0000dc12_9518522259818270</td>\n",
              "      <td>1</td>\n",
              "      <td>367585191-9.51852225982e+15</td>\n",
              "      <td>1</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>de</td>\n",
              "      <td>True</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3F9SfDyofskDPna8R</td>\n",
              "      <td>Footbridge</td>\n",
              "      <td>0000dc12_9518522259818270</td>\n",
              "      <td>0</td>\n",
              "      <td>367585191-9.51852225982e+15</td>\n",
              "      <td>2</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>de</td>\n",
              "      <td>True</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oz9anPbE6e52TKuJy</td>\n",
              "      <td>Switch</td>\n",
              "      <td>0000dc12_9518522259818270</td>\n",
              "      <td>1</td>\n",
              "      <td>367585191-9.51852225982e+15</td>\n",
              "      <td>3</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>de</td>\n",
              "      <td>True</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dkAhBaLhzi62Pp6Hp</td>\n",
              "      <td>Footbridge</td>\n",
              "      <td>0002ae2d_2286850331484848</td>\n",
              "      <td>0</td>\n",
              "      <td>1654499857-2.28685033148e+15</td>\n",
              "      <td>1</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>True</td>\n",
              "      <td>GB</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2ussgtw7vCZMNjxSJ</td>\n",
              "      <td>Switch</td>\n",
              "      <td>0002ae2d_2286850331484848</td>\n",
              "      <td>1</td>\n",
              "      <td>1654499857-2.28685033148e+15</td>\n",
              "      <td>2</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>True</td>\n",
              "      <td>GB</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 _id    Scenario  ... country_code    country_full\n",
              "0  C3RGCjGPftjMKYHy2        Loop  ...           DE         Germany\n",
              "1  3F9SfDyofskDPna8R  Footbridge  ...           DE         Germany\n",
              "2  oz9anPbE6e52TKuJy      Switch  ...           DE         Germany\n",
              "3  dkAhBaLhzi62Pp6Hp  Footbridge  ...           GB  United Kingdom\n",
              "4  2ussgtw7vCZMNjxSJ      Switch  ...           GB  United Kingdom\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FviDtwHvwBn"
      },
      "source": [
        "filtered = df.drop(['Session_id','Template','country_full','_id','answerLeft'], axis=1)\r\n",
        "filtered.dropna()\r\n",
        "filtered.replace('Loop',0,inplace=True)   #0 is loop trolley \r\n",
        "filtered.replace('Footbridge',1,inplace=True) #1 is footbridge trolley\r\n",
        "filtered.replace('Switch',2,inplace=True) #2 is standard trolley\r\n",
        "\r\n",
        "lang = dict()\r\n",
        "country = dict()\r\n",
        "iLang = 0\r\n",
        "iCountry = 0\r\n",
        "for index, x in filtered.iterrows():\r\n",
        "  if x[\"lang\"] not in lang.keys():\r\n",
        "    lang[x[\"lang\"]] = iLang\r\n",
        "    iLang = iLang + 1\r\n",
        "  if x[\"country_code\"] not in country.keys():\r\n",
        "    country[x[\"country_code\"]] = iCountry\r\n",
        "    iCountry = iCountry + 1\r\n",
        "for key, value in country.items():\r\n",
        "  filtered.replace(key,int(value),inplace=True)\r\n",
        "for key, value in lang.items():\r\n",
        "  filtered.replace(key,int(value),inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0N3HQkv_ee0"
      },
      "source": [
        "filtered['country_code'] = filtered['country_code'].astype(int)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm0NARn3yBNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dd47a8d-7875-4cf5-c57f-9696699b9935"
      },
      "source": [
        "filtered.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 230475 entries, 0 to 230474\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   Scenario        230475 non-null  int64 \n",
            " 1   UserID          230475 non-null  object\n",
            " 2   Outcome         230475 non-null  int64 \n",
            " 3   Scenario_order  230475 non-null  int64 \n",
            " 4   lang            230475 non-null  int64 \n",
            " 5   seenOther       230475 non-null  bool  \n",
            " 6   country_code    230475 non-null  int64 \n",
            "dtypes: bool(1), int64(5), object(1)\n",
            "memory usage: 10.8+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyzpqvimWmly",
        "outputId": "a0113548-55c5-4738-c12c-24af6dd6b289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "filtered.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Scenario</th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Scenario_order</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>230475.000000</td>\n",
              "      <td>230475.000000</td>\n",
              "      <td>230475.000000</td>\n",
              "      <td>230475.000000</td>\n",
              "      <td>230475.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.997896</td>\n",
              "      <td>0.700453</td>\n",
              "      <td>1.955301</td>\n",
              "      <td>1.903946</td>\n",
              "      <td>15.234290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.816945</td>\n",
              "      <td>0.458060</td>\n",
              "      <td>0.817113</td>\n",
              "      <td>1.716888</td>\n",
              "      <td>22.201642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>169.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Scenario        Outcome  ...           lang   country_code\n",
              "count  230475.000000  230475.000000  ...  230475.000000  230475.000000\n",
              "mean        0.997896       0.700453  ...       1.903946      15.234290\n",
              "std         0.816945       0.458060  ...       1.716888      22.201642\n",
              "min         0.000000       0.000000  ...       0.000000       0.000000\n",
              "25%         0.000000       0.000000  ...       1.000000       3.000000\n",
              "50%         1.000000       1.000000  ...       1.000000       6.000000\n",
              "75%         2.000000       1.000000  ...       3.000000      21.000000\n",
              "max         2.000000       1.000000  ...       9.000000     169.000000\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEpYHsu_yXK3"
      },
      "source": [
        "def create_dataset(X):\r\n",
        "  Xs = X.drop([\"UserID\",\"Outcome\"],axis = 1)\r\n",
        "  Ys = X.drop([\"Scenario\",\"UserID\",\"Scenario_order\",\"lang\",\"seenOther\",\"country_code\"],axis=1)\r\n",
        "  Xs,Ys = Xs.astype(int),Ys.astype(int)\r\n",
        "  Xs['seenOther'] = Xs['seenOther'].astype(bool)\r\n",
        "  Ys['Outcome'] = Ys['Outcome'].astype(bool)\r\n",
        "  return Xs,Ys"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwkZ4piry95T"
      },
      "source": [
        "interval = int(len(filtered.index)/3)\r\n",
        "x_train, y_train = create_dataset(filtered.head(interval))\r\n",
        "x_test, y_test = create_dataset(filtered.tail(interval))\r\n",
        "x_val, y_val = create_dataset(filtered.loc[interval:interval*2])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGuV2WIdcvAo",
        "outputId": "74ee4576-d639-4de8-9406-d5c961c1ed4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_train.info()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76825 entries, 0 to 76824\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype\n",
            "---  ------          --------------  -----\n",
            " 0   Scenario        76825 non-null  int64\n",
            " 1   Scenario_order  76825 non-null  int64\n",
            " 2   lang            76825 non-null  int64\n",
            " 3   seenOther       76825 non-null  bool \n",
            " 4   country_code    76825 non-null  int64\n",
            "dtypes: bool(1), int64(4)\n",
            "memory usage: 2.4 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDo92e6sc8Fg",
        "outputId": "081c3c0c-b82b-4c85-cc5d-a376d6be979e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_train.info()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 76825 entries, 0 to 76824\n",
            "Data columns (total 1 columns):\n",
            " #   Column   Non-Null Count  Dtype\n",
            "---  ------   --------------  -----\n",
            " 0   Outcome  76825 non-null  bool \n",
            "dtypes: bool(1)\n",
            "memory usage: 75.1 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJHX5VJ1P32"
      },
      "source": [
        "# **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3_DTObO1gvC"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras import layers\r\n",
        "from keras.layers import LSTM, Dense,Conv1D,MaxPooling1D,Flatten\r\n",
        "from keras.optimizers import RMSprop,SGD\r\n",
        "from tensorflow import keras\r\n",
        "from keras import optimizers\r\n",
        "import tensorflow as tf"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5EhPCp6FGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e4ee282-df20-4dd6-fb31-0267fec180c3"
      },
      "source": [
        "def create_model():\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(100, input_dim=5, activation='relu'))\r\n",
        "  model.add(Dense(50, activation='sigmoid'))\r\n",
        "  model.add(Dense(1, activation='sigmoid'))\r\n",
        "  model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])\r\n",
        "  return model\r\n",
        "\r\n",
        "estimators = []\r\n",
        "estimators.append(('standardize', StandardScaler()))\r\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=10, batch_size=100, verbose=1)))\r\n",
        "pipeline = Pipeline(estimators)\r\n",
        "kfold = StratifiedKFold(n_splits=2, shuffle=True)\r\n",
        "results = cross_val_score(pipeline, x_train, y_train, cv=kfold)\r\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "38412/38412 [==============================] - 1s 37us/step - loss: 0.6212 - accuracy: 0.6817\n",
            "Epoch 2/10\n",
            "38412/38412 [==============================] - 1s 27us/step - loss: 0.6093 - accuracy: 0.7006\n",
            "Epoch 3/10\n",
            "38412/38412 [==============================] - 1s 25us/step - loss: 0.6087 - accuracy: 0.7006\n",
            "Epoch 4/10\n",
            "38412/38412 [==============================] - 1s 27us/step - loss: 0.6081 - accuracy: 0.7006\n",
            "Epoch 5/10\n",
            "38412/38412 [==============================] - 1s 29us/step - loss: 0.6075 - accuracy: 0.7006\n",
            "Epoch 6/10\n",
            "38412/38412 [==============================] - 1s 30us/step - loss: 0.6070 - accuracy: 0.7006\n",
            "Epoch 7/10\n",
            "38412/38412 [==============================] - 1s 27us/step - loss: 0.6065 - accuracy: 0.7006\n",
            "Epoch 8/10\n",
            "38412/38412 [==============================] - 1s 27us/step - loss: 0.6060 - accuracy: 0.7006\n",
            "Epoch 9/10\n",
            "38412/38412 [==============================] - 1s 29us/step - loss: 0.6055 - accuracy: 0.7006\n",
            "Epoch 10/10\n",
            "38412/38412 [==============================] - 1s 27us/step - loss: 0.6051 - accuracy: 0.7006\n",
            "38413/38413 [==============================] - 1s 27us/step\n",
            "Epoch 1/10\n",
            "38413/38413 [==============================] - 1s 37us/step - loss: 0.6195 - accuracy: 0.6833\n",
            "Epoch 2/10\n",
            "38413/38413 [==============================] - 1s 27us/step - loss: 0.6085 - accuracy: 0.7006\n",
            "Epoch 3/10\n",
            "38413/38413 [==============================] - 1s 27us/step - loss: 0.6075 - accuracy: 0.7006\n",
            "Epoch 4/10\n",
            "38413/38413 [==============================] - 1s 29us/step - loss: 0.6066 - accuracy: 0.7006\n",
            "Epoch 5/10\n",
            "38413/38413 [==============================] - 1s 31us/step - loss: 0.6057 - accuracy: 0.7006\n",
            "Epoch 6/10\n",
            "38413/38413 [==============================] - 1s 29us/step - loss: 0.6049 - accuracy: 0.7006\n",
            "Epoch 7/10\n",
            "38413/38413 [==============================] - 1s 27us/step - loss: 0.6041 - accuracy: 0.7006\n",
            "Epoch 8/10\n",
            "38413/38413 [==============================] - 1s 25us/step - loss: 0.6032 - accuracy: 0.7006\n",
            "Epoch 9/10\n",
            "38413/38413 [==============================] - 1s 26us/step - loss: 0.6026 - accuracy: 0.7006\n",
            "Epoch 10/10\n",
            "38413/38413 [==============================] - 1s 27us/step - loss: 0.6018 - accuracy: 0.7006\n",
            "38412/38412 [==============================] - 1s 27us/step\n",
            "Results: 70.06% (0.00%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V89Ylk9L20S2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd3caf5-1d88-4200-af41-388c130b903e"
      },
      "source": [
        "#Basic\r\n",
        "model = Sequential()\r\n",
        "model.add(Dense(60, input_dim=5, activation='relu'))\r\n",
        "model.add(Dense(40, activation='relu'))\r\n",
        "model.add(Dense(10, activation='sigmoid'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "history = model.fit(x_train,y_train,epochs=10, validation_data=(x_val,y_val),batch_size=50)\r\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (acc*100, loss*100))"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 76825 samples, validate on 76826 samples\n",
            "Epoch 1/10\n",
            "76825/76825 [==============================] - 8s 100us/step - loss: 0.5949 - accuracy: 0.7006 - val_loss: 0.5873 - val_accuracy: 0.6981\n",
            "Epoch 2/10\n",
            "76825/76825 [==============================] - 7s 87us/step - loss: 0.5806 - accuracy: 0.7015 - val_loss: 0.5787 - val_accuracy: 0.7006\n",
            "Epoch 3/10\n",
            "76825/76825 [==============================] - 7s 91us/step - loss: 0.5788 - accuracy: 0.7013 - val_loss: 0.5789 - val_accuracy: 0.7010\n",
            "Epoch 4/10\n",
            "76825/76825 [==============================] - 7s 91us/step - loss: 0.5780 - accuracy: 0.7020 - val_loss: 0.5818 - val_accuracy: 0.6989\n",
            "Epoch 5/10\n",
            "76825/76825 [==============================] - 7s 91us/step - loss: 0.5779 - accuracy: 0.7020 - val_loss: 0.5846 - val_accuracy: 0.6992\n",
            "Epoch 6/10\n",
            "76825/76825 [==============================] - 7s 92us/step - loss: 0.5773 - accuracy: 0.7019 - val_loss: 0.5793 - val_accuracy: 0.7007\n",
            "Epoch 7/10\n",
            "76825/76825 [==============================] - 7s 96us/step - loss: 0.5772 - accuracy: 0.7033 - val_loss: 0.5787 - val_accuracy: 0.7017\n",
            "Epoch 8/10\n",
            "76825/76825 [==============================] - 7s 95us/step - loss: 0.5771 - accuracy: 0.7025 - val_loss: 0.5783 - val_accuracy: 0.7025\n",
            "Epoch 9/10\n",
            "76825/76825 [==============================] - 7s 91us/step - loss: 0.5770 - accuracy: 0.7016 - val_loss: 0.5785 - val_accuracy: 0.7020\n",
            "Epoch 10/10\n",
            "76825/76825 [==============================] - 7s 89us/step - loss: 0.5768 - accuracy: 0.7024 - val_loss: 0.5786 - val_accuracy: 0.7023\n",
            "Results: 70.46% (57.79%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUF7hbQky_ld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "0c9d370c-f773-4478-f4d5-6430241596ef"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(12, input_dim=5, activation='relu'))\r\n",
        "model.add(Dense(8, activation='relu'))\r\n",
        "model.add(Dense(1, activation='sigmoid'))\r\n",
        "# compile the keras model\r\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "# fit the keras model on the dataset\r\n",
        "model.fit(x_train, y_train, epochs=50, batch_size=25)\r\n",
        "# evaluate the keras model\r\n",
        "_, accuracy = model.evaluate(x_test, y_test)\r\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "76825/76825 [==============================] - 9s 118us/step - loss: 0.6091 - accuracy: 0.6966\n",
            "Epoch 2/50\n",
            "76825/76825 [==============================] - 8s 110us/step - loss: 0.5882 - accuracy: 0.6995\n",
            "Epoch 3/50\n",
            "76825/76825 [==============================] - 9s 120us/step - loss: 0.5840 - accuracy: 0.6996\n",
            "Epoch 4/50\n",
            "76825/76825 [==============================] - 8s 103us/step - loss: 0.5825 - accuracy: 0.7001\n",
            "Epoch 5/50\n",
            "76825/76825 [==============================] - 8s 101us/step - loss: 0.5812 - accuracy: 0.7000\n",
            "Epoch 6/50\n",
            "34875/76825 [============>.................] - ETA: 4s - loss: 0.5812 - accuracy: 0.7007\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-113-ab683c949b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# fit the keras model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;31m# evaluate the keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    364\u001b[0m         \"\"\"\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# For backwards compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0;31m# will be handled by on_epoch_end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, current, values)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0mprev_total_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\b'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    503\u001b[0m                 )\n\u001b[1;32m    504\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q2EuIaBs5up"
      },
      "source": [
        "# Epochs vs Batch Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTgXju1bcxa"
      },
      "source": [
        "def buildModel():\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Dense(60, input_dim=5, activation='relu'))\r\n",
        "  model.add(Dense(40, activation='relu'))\r\n",
        "  model.add(Dense(10, activation='sigmoid'))\r\n",
        "  model.add(Dense(1, activation='sigmoid'))\r\n",
        "  return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZW3TBSLtrtZ",
        "outputId": "ef9d8b81-718c-46e3-dd4c-59b0413874c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "acc = dict()\r\n",
        "for batch in range(1,15): #batch size \r\n",
        "  for epoch in range(1,15): #epochs\r\n",
        "    print(\"Epochs: {0} \\t Batch Size: {1}\".format(10*epoch,16*batch))\r\n",
        "    model = buildModel()\r\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\r\n",
        "    model.fit(x_train, y_train, epochs=(10*epoch), batch_size=(16*batch),verbose=0)\r\n",
        "    loss, accuracy = model.evaluate(x_test, y_test,verbose=0)\r\n",
        "    key = \"epochs{0}batch{1}\".format(10*epoch,16*batch)\r\n",
        "    acc[key] = accuracy*100\r\n",
        "    print('Accuracy: %.2f%%' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 10 \t Batch Size: 16\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Accuracy: 70.39%\n",
            "Epochs: 20 \t Batch Size: 16\n",
            "Accuracy: 70.27%\n",
            "Epochs: 30 \t Batch Size: 16\n",
            "Accuracy: 70.59%\n",
            "Epochs: 40 \t Batch Size: 16\n",
            "Accuracy: 70.60%\n",
            "Epochs: 50 \t Batch Size: 16\n",
            "Accuracy: 70.44%\n",
            "Epochs: 60 \t Batch Size: 16\n",
            "Accuracy: 70.70%\n",
            "Epochs: 70 \t Batch Size: 16\n",
            "Accuracy: 70.38%\n",
            "Epochs: 80 \t Batch Size: 16\n",
            "Accuracy: 70.79%\n",
            "Epochs: 90 \t Batch Size: 16\n",
            "Accuracy: 70.85%\n",
            "Epochs: 100 \t Batch Size: 16\n",
            "Accuracy: 70.80%\n",
            "Epochs: 110 \t Batch Size: 16\n",
            "Accuracy: 70.66%\n",
            "Epochs: 120 \t Batch Size: 16\n",
            "Accuracy: 70.85%\n",
            "Epochs: 130 \t Batch Size: 16\n",
            "Accuracy: 70.72%\n",
            "Epochs: 140 \t Batch Size: 16\n",
            "Accuracy: 70.70%\n",
            "Epochs: 10 \t Batch Size: 32\n",
            "Accuracy: 70.41%\n",
            "Epochs: 20 \t Batch Size: 32\n",
            "Accuracy: 70.28%\n",
            "Epochs: 30 \t Batch Size: 32\n",
            "Accuracy: 70.56%\n",
            "Epochs: 40 \t Batch Size: 32\n",
            "Accuracy: 70.51%\n",
            "Epochs: 50 \t Batch Size: 32\n",
            "Accuracy: 70.69%\n",
            "Epochs: 60 \t Batch Size: 32\n",
            "Accuracy: 70.75%\n",
            "Epochs: 70 \t Batch Size: 32\n",
            "Accuracy: 70.74%\n",
            "Epochs: 80 \t Batch Size: 32\n",
            "Accuracy: 70.78%\n",
            "Epochs: 90 \t Batch Size: 32\n",
            "Accuracy: 70.76%\n",
            "Epochs: 100 \t Batch Size: 32\n",
            "Accuracy: 70.73%\n",
            "Epochs: 110 \t Batch Size: 32\n",
            "Accuracy: 70.74%\n",
            "Epochs: 120 \t Batch Size: 32\n",
            "Accuracy: 70.78%\n",
            "Epochs: 130 \t Batch Size: 32\n",
            "Accuracy: 70.62%\n",
            "Epochs: 140 \t Batch Size: 32\n",
            "Accuracy: 70.75%\n",
            "Epochs: 10 \t Batch Size: 48\n",
            "Accuracy: 70.37%\n",
            "Epochs: 20 \t Batch Size: 48\n",
            "Accuracy: 70.40%\n",
            "Epochs: 30 \t Batch Size: 48\n",
            "Accuracy: 70.52%\n",
            "Epochs: 40 \t Batch Size: 48\n",
            "Accuracy: 70.59%\n",
            "Epochs: 50 \t Batch Size: 48\n",
            "Accuracy: 70.52%\n",
            "Epochs: 60 \t Batch Size: 48\n",
            "Accuracy: 70.72%\n",
            "Epochs: 70 \t Batch Size: 48\n",
            "Accuracy: 70.80%\n",
            "Epochs: 80 \t Batch Size: 48\n",
            "Accuracy: 70.76%\n",
            "Epochs: 90 \t Batch Size: 48\n",
            "Accuracy: 70.77%\n",
            "Epochs: 100 \t Batch Size: 48\n",
            "Accuracy: 70.72%\n",
            "Epochs: 110 \t Batch Size: 48\n",
            "Accuracy: 70.85%\n",
            "Epochs: 120 \t Batch Size: 48\n",
            "Accuracy: 70.65%\n",
            "Epochs: 130 \t Batch Size: 48\n",
            "Accuracy: 70.63%\n",
            "Epochs: 140 \t Batch Size: 48\n",
            "Accuracy: 70.79%\n",
            "Epochs: 10 \t Batch Size: 64\n",
            "Accuracy: 70.35%\n",
            "Epochs: 20 \t Batch Size: 64\n",
            "Accuracy: 70.44%\n",
            "Epochs: 30 \t Batch Size: 64\n",
            "Accuracy: 70.47%\n",
            "Epochs: 40 \t Batch Size: 64\n",
            "Accuracy: 70.66%\n",
            "Epochs: 50 \t Batch Size: 64\n",
            "Accuracy: 70.62%\n",
            "Epochs: 60 \t Batch Size: 64\n",
            "Accuracy: 70.78%\n",
            "Epochs: 70 \t Batch Size: 64\n",
            "Accuracy: 70.55%\n",
            "Epochs: 80 \t Batch Size: 64\n",
            "Accuracy: 70.78%\n",
            "Epochs: 90 \t Batch Size: 64\n",
            "Accuracy: 70.78%\n",
            "Epochs: 100 \t Batch Size: 64\n",
            "Accuracy: 70.76%\n",
            "Epochs: 110 \t Batch Size: 64\n",
            "Accuracy: 70.59%\n",
            "Epochs: 120 \t Batch Size: 64\n",
            "Accuracy: 70.76%\n",
            "Epochs: 130 \t Batch Size: 64\n",
            "Accuracy: 70.70%\n",
            "Epochs: 140 \t Batch Size: 64\n",
            "Accuracy: 70.74%\n",
            "Epochs: 10 \t Batch Size: 80\n",
            "Accuracy: 70.30%\n",
            "Epochs: 20 \t Batch Size: 80\n",
            "Accuracy: 70.45%\n",
            "Epochs: 30 \t Batch Size: 80\n",
            "Accuracy: 70.51%\n",
            "Epochs: 40 \t Batch Size: 80\n",
            "Accuracy: 70.67%\n",
            "Epochs: 50 \t Batch Size: 80\n",
            "Accuracy: 70.47%\n",
            "Epochs: 60 \t Batch Size: 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0uqCRV5u3DI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}