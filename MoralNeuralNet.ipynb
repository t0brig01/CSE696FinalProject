{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MoralNeuralNet.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOPOk3Kv2dA72uFXvZ8QwiV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/t0brig01/CSE696FinalProject/blob/main/MoralNeuralNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zrLBI6pAHL1",
        "outputId": "5313ab6b-4620-416a-aeae-c529953798b8"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import concat\n",
        "from sklearn import preprocessing\n",
        "import matplotlib.pyplot as plt\n",
        "print (\"TensorFlow version: \" + tf.__version__)\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
        "from imblearn.over_sampling import SMOTE as smt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "TensorFlow version: 1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLV79Vb5pZVs"
      },
      "source": [
        "# Extra visual functions for data analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn7LkcQxpftP"
      },
      "source": [
        "def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n",
        "    nunique = df.nunique()\n",
        "    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n",
        "    nRow, nCol = df.shape\n",
        "    columnNames = list(df)\n",
        "    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow\n",
        "    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n",
        "    for i in range(min(nCol, nGraphShown)):\n",
        "        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n",
        "        columnDf = df.iloc[:, i]\n",
        "        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n",
        "            valueCounts = columnDf.value_counts()\n",
        "            valueCounts.plot.bar()\n",
        "        else:\n",
        "            columnDf.hist()\n",
        "        plt.ylabel('counts')\n",
        "        plt.xticks(rotation = 90)\n",
        "        plt.title(f'{columnNames[i]} (column {i})')\n",
        "    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YnPk2OLpkry"
      },
      "source": [
        "def plotCorrelationMatrix(df, graphWidth):\n",
        "    df = df.dropna('columns') # drop columns with NaN\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    if df.shape[1] < 2:\n",
        "        print(f'No correlation plots shown: The number of non-NaN or constant columns ({df.shape[1]}) is less than 2')\n",
        "        return\n",
        "    corr = df.corr()\n",
        "    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')\n",
        "    corrMat = plt.matshow(corr, fignum = 1)\n",
        "    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
        "    plt.yticks(range(len(corr.columns)), corr.columns)\n",
        "    plt.gca().xaxis.tick_bottom()\n",
        "    plt.colorbar(corrMat)\n",
        "    plt.title(f'Correlation Matrix', fontsize=15)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IRByU_fpnXX"
      },
      "source": [
        "def plotScatterMatrix(df, plotSize, textSize):\n",
        "    df = df.select_dtypes(include =[np.number]) # keep only numerical columns\n",
        "    # Remove rows and columns that would lead to df being singular\n",
        "    df = df.dropna('columns')\n",
        "    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values\n",
        "    columnNames = list(df)\n",
        "    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots\n",
        "        columnNames = columnNames[:10]\n",
        "    df = df[columnNames]\n",
        "    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')\n",
        "    corrs = df.corr().values\n",
        "    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):\n",
        "        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)\n",
        "    plt.suptitle('Scatter and Density Plot')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZVH15Vu1R88"
      },
      "source": [
        "# **Data Loading/Manipulation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yfK1H0OvFez"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/t0brig01/CSE696FinalProject/main/TrolleyData.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZjiIHOveFM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f4f769-6819-41f3-c5da-95d40865afde"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 230475 entries, 0 to 230474\n",
            "Data columns (total 12 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   _id             230475 non-null  object\n",
            " 1   Scenario        230475 non-null  object\n",
            " 2   UserID          230475 non-null  object\n",
            " 3   Outcome         230475 non-null  int64 \n",
            " 4   Session_id      230475 non-null  object\n",
            " 5   Scenario_order  230475 non-null  int64 \n",
            " 6   Template        230475 non-null  object\n",
            " 7   answerLeft      230475 non-null  bool  \n",
            " 8   lang            230475 non-null  object\n",
            " 9   seenOther       230475 non-null  bool  \n",
            " 10  country_code    229259 non-null  object\n",
            " 11  country_full    229259 non-null  object\n",
            "dtypes: bool(2), int64(2), object(8)\n",
            "memory usage: 18.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WgRLKBDvfEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f55520f1-41a7-4a2c-b99d-bfcf65e843fd"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>_id</th>\n",
              "      <th>Scenario</th>\n",
              "      <th>UserID</th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Session_id</th>\n",
              "      <th>Scenario_order</th>\n",
              "      <th>Template</th>\n",
              "      <th>answerLeft</th>\n",
              "      <th>lang</th>\n",
              "      <th>seenOther</th>\n",
              "      <th>country_code</th>\n",
              "      <th>country_full</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C3RGCjGPftjMKYHy2</td>\n",
              "      <td>Loop</td>\n",
              "      <td>0000dc12_9518522259818270</td>\n",
              "      <td>1</td>\n",
              "      <td>367585191-9.51852225982e+15</td>\n",
              "      <td>1</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>de</td>\n",
              "      <td>True</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3F9SfDyofskDPna8R</td>\n",
              "      <td>Footbridge</td>\n",
              "      <td>0000dc12_9518522259818270</td>\n",
              "      <td>0</td>\n",
              "      <td>367585191-9.51852225982e+15</td>\n",
              "      <td>2</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>de</td>\n",
              "      <td>True</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>oz9anPbE6e52TKuJy</td>\n",
              "      <td>Switch</td>\n",
              "      <td>0000dc12_9518522259818270</td>\n",
              "      <td>1</td>\n",
              "      <td>367585191-9.51852225982e+15</td>\n",
              "      <td>3</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>de</td>\n",
              "      <td>True</td>\n",
              "      <td>DE</td>\n",
              "      <td>Germany</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dkAhBaLhzi62Pp6Hp</td>\n",
              "      <td>Footbridge</td>\n",
              "      <td>0002ae2d_2286850331484848</td>\n",
              "      <td>0</td>\n",
              "      <td>1654499857-2.28685033148e+15</td>\n",
              "      <td>1</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>True</td>\n",
              "      <td>GB</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2ussgtw7vCZMNjxSJ</td>\n",
              "      <td>Switch</td>\n",
              "      <td>0002ae2d_2286850331484848</td>\n",
              "      <td>1</td>\n",
              "      <td>1654499857-2.28685033148e+15</td>\n",
              "      <td>2</td>\n",
              "      <td>Desktop</td>\n",
              "      <td>False</td>\n",
              "      <td>en</td>\n",
              "      <td>True</td>\n",
              "      <td>GB</td>\n",
              "      <td>United Kingdom</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 _id    Scenario  ... country_code    country_full\n",
              "0  C3RGCjGPftjMKYHy2        Loop  ...           DE         Germany\n",
              "1  3F9SfDyofskDPna8R  Footbridge  ...           DE         Germany\n",
              "2  oz9anPbE6e52TKuJy      Switch  ...           DE         Germany\n",
              "3  dkAhBaLhzi62Pp6Hp  Footbridge  ...           GB  United Kingdom\n",
              "4  2ussgtw7vCZMNjxSJ      Switch  ...           GB  United Kingdom\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FviDtwHvwBn"
      },
      "source": [
        "filtered = df.drop(['Session_id','Template','country_full','_id','answerLeft'], axis=1)\n",
        "filtered.dropna(inplace=True)\n",
        "filtered.replace('Loop',0,inplace=True)   #0 is loop trolley \n",
        "filtered.replace('Footbridge',1,inplace=True) #1 is footbridge trolley\n",
        "filtered.replace('Switch',2,inplace=True) #2 is standard trolley\n",
        "\n",
        "lang = dict()\n",
        "country = dict()\n",
        "iLang = 0\n",
        "iCountry = 0\n",
        "for index, x in filtered.iterrows():\n",
        "  if x[\"country_code\"] == \"-\":\n",
        "    filtered.drop(index,inplace=True)\n",
        "    continue\n",
        "  if x[\"lang\"] not in lang.keys():\n",
        "    lang[x[\"lang\"]] = iLang\n",
        "    iLang = iLang + 1\n",
        "  if x[\"country_code\"] not in country.keys():\n",
        "    country[x[\"country_code\"]] = iCountry\n",
        "    iCountry = iCountry + 1\n",
        "for key, value in country.items():\n",
        "  filtered.replace(key,int(value),inplace=True)\n",
        "for key, value in lang.items():\n",
        "  filtered.replace(key,int(value),inplace=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0N3HQkv_ee0"
      },
      "source": [
        "filtered['country_code'] = filtered['country_code'].astype(int)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vm0NARn3yBNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68f4f363-3326-4906-bc63-4ed234502945"
      },
      "source": [
        "filtered.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 228990 entries, 0 to 229258\n",
            "Data columns (total 7 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   Scenario        228990 non-null  int64 \n",
            " 1   UserID          228990 non-null  object\n",
            " 2   Outcome         228990 non-null  int64 \n",
            " 3   Scenario_order  228990 non-null  int64 \n",
            " 4   lang            228990 non-null  int64 \n",
            " 5   seenOther       228990 non-null  bool  \n",
            " 6   country_code    228990 non-null  int64 \n",
            "dtypes: bool(1), int64(5), object(1)\n",
            "memory usage: 12.4+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyzpqvimWmly",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "7bd1e11a-0aa0-4c16-a792-b70367d17ded"
      },
      "source": [
        "filtered.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Scenario</th>\n",
              "      <th>Outcome</th>\n",
              "      <th>Scenario_order</th>\n",
              "      <th>lang</th>\n",
              "      <th>country_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>228990.000000</td>\n",
              "      <td>228990.000000</td>\n",
              "      <td>228990.000000</td>\n",
              "      <td>228990.000000</td>\n",
              "      <td>228990.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.998218</td>\n",
              "      <td>0.700074</td>\n",
              "      <td>1.955950</td>\n",
              "      <td>1.906005</td>\n",
              "      <td>14.331189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.816972</td>\n",
              "      <td>0.458226</td>\n",
              "      <td>0.817067</td>\n",
              "      <td>1.719647</td>\n",
              "      <td>19.048477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>21.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>167.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Scenario        Outcome  ...           lang   country_code\n",
              "count  228990.000000  228990.000000  ...  228990.000000  228990.000000\n",
              "mean        0.998218       0.700074  ...       1.906005      14.331189\n",
              "std         0.816972       0.458226  ...       1.719647      19.048477\n",
              "min         0.000000       0.000000  ...       0.000000       0.000000\n",
              "25%         0.000000       0.000000  ...       1.000000       3.000000\n",
              "50%         1.000000       1.000000  ...       1.000000       6.000000\n",
              "75%         2.000000       1.000000  ...       3.000000      21.000000\n",
              "max         2.000000       1.000000  ...       9.000000     167.000000\n",
              "\n",
              "[8 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCG6sVBCpu0C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "1ca85cb9-2fc0-49c2-ce3d-bc057a05b175"
      },
      "source": [
        "plotPerColumnDistribution(filtered, 10, 10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0009cf6f982a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplotPerColumnDistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'plotPerColumnDistribution' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOdNLeRppvQ7"
      },
      "source": [
        "plotCorrelationMatrix(filtered, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlD3FfcJpvbX"
      },
      "source": [
        "plotScatterMatrix(filtered, 20, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEpYHsu_yXK3"
      },
      "source": [
        "def create_dataset(X):\n",
        "  \n",
        "  Xs = X.drop([\"UserID\",\"Outcome\"],axis = 1)\n",
        "  Ys = X.drop([\"Scenario\",\"UserID\",\"Scenario_order\",\"lang\",\"seenOther\",\"country_code\"],axis=1)\n",
        "  Xs,Ys = Xs.astype(float),Ys.astype(float)\n",
        "  encoder = LabelEncoder()\n",
        "  encoder.fit(Ys)\n",
        "  Ys = encoder.transform(Ys)\n",
        "  return Xs,Ys"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwkZ4piry95T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1e76c32-65bf-44d5-994d-87998d9fe05a"
      },
      "source": [
        "interval = int(len(filtered.index)/3)\n",
        "filtered = filtered.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "x_train, y_train = create_dataset(filtered.head(2*interval))\n",
        "# x_test, y_test = create_dataset(filtered.tail(interval))\n",
        "x_val, y_val = create_dataset(filtered.loc[interval:interval*2])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGuV2WIdcvAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eae4bc75-e5d4-4dd3-9928-cbb247432656"
      },
      "source": [
        "x_train.info()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 152660 entries, 0 to 152659\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count   Dtype  \n",
            "---  ------          --------------   -----  \n",
            " 0   Scenario        152660 non-null  float64\n",
            " 1   Scenario_order  152660 non-null  float64\n",
            " 2   lang            152660 non-null  float64\n",
            " 3   seenOther       152660 non-null  float64\n",
            " 4   country_code    152660 non-null  float64\n",
            "dtypes: float64(5)\n",
            "memory usage: 5.8 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhcUiEebCwWv",
        "outputId": "321e969f-8104-410a-d73b-7cf6a49e0c6d"
      },
      "source": [
        "np.sum(y_train == 0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45813"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJHX5VJ1P32"
      },
      "source": [
        "# **Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3_DTObO1gvC"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import LSTM, Dense,Conv1D,MaxPooling1D,Flatten,Activation,BatchNormalization,Dropout\n",
        "from keras.optimizers import RMSprop,SGD,Adam,Nadam\n",
        "from tensorflow import keras\n",
        "from keras import optimizers\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w5EhPCp6FGm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7891be65-8625-4d07-8968-d41d64f408a7"
      },
      "source": [
        "#BEST\n",
        "def create_model():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(50,input_dim=5, activation='relu',kernel_initializer='random_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(140, activation='relu',kernel_initializer='random_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(70, activation='relu',kernel_initializer='random_uniform'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid',kernel_initializer='random_uniform'))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=3000)\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', model))\n",
        "pipeline = Pipeline(estimators)\n",
        "pipeline.fit(x_train,y_train)\n",
        "kfold = StratifiedKFold(n_splits=4, shuffle=True)\n",
        "results = cross_val_score(pipeline, x_val, y_val, cv=kfold)\n",
        "print(\"Cross-validation evaluations\")\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "152660/152660 [==============================] - 2s 14us/step - loss: 0.6501 - accuracy: 0.6435\n",
            "Epoch 2/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.6064 - accuracy: 0.6780\n",
            "Epoch 3/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5805 - accuracy: 0.7013\n",
            "Epoch 4/100\n",
            "152660/152660 [==============================] - 1s 10us/step - loss: 0.5764 - accuracy: 0.7054\n",
            "Epoch 5/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5757 - accuracy: 0.7063\n",
            "Epoch 6/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5753 - accuracy: 0.7057\n",
            "Epoch 7/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5750 - accuracy: 0.7062\n",
            "Epoch 8/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5746 - accuracy: 0.7065\n",
            "Epoch 9/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5743 - accuracy: 0.7066\n",
            "Epoch 10/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5745 - accuracy: 0.7065\n",
            "Epoch 11/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5743 - accuracy: 0.7061\n",
            "Epoch 12/100\n",
            "152660/152660 [==============================] - 1s 10us/step - loss: 0.5740 - accuracy: 0.7071\n",
            "Epoch 13/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5739 - accuracy: 0.7064\n",
            "Epoch 14/100\n",
            "152660/152660 [==============================] - 1s 10us/step - loss: 0.5740 - accuracy: 0.7070\n",
            "Epoch 15/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5739 - accuracy: 0.7067\n",
            "Epoch 16/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5738 - accuracy: 0.7071\n",
            "Epoch 17/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5738 - accuracy: 0.7067\n",
            "Epoch 18/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5736 - accuracy: 0.7066\n",
            "Epoch 19/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5735 - accuracy: 0.7067\n",
            "Epoch 20/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5735 - accuracy: 0.7071\n",
            "Epoch 21/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5733 - accuracy: 0.7069\n",
            "Epoch 22/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5734 - accuracy: 0.7068\n",
            "Epoch 23/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5733 - accuracy: 0.7067\n",
            "Epoch 24/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5733 - accuracy: 0.7070\n",
            "Epoch 25/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5731 - accuracy: 0.7072\n",
            "Epoch 26/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5732 - accuracy: 0.7074\n",
            "Epoch 27/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5731 - accuracy: 0.7073\n",
            "Epoch 28/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5731 - accuracy: 0.7069\n",
            "Epoch 29/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5729 - accuracy: 0.7078\n",
            "Epoch 30/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5730 - accuracy: 0.7074\n",
            "Epoch 31/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5731 - accuracy: 0.7071\n",
            "Epoch 32/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5730 - accuracy: 0.7072\n",
            "Epoch 33/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5728 - accuracy: 0.7072\n",
            "Epoch 34/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5729 - accuracy: 0.7075\n",
            "Epoch 35/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5728 - accuracy: 0.7073\n",
            "Epoch 36/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5728 - accuracy: 0.7072\n",
            "Epoch 37/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5728 - accuracy: 0.7071\n",
            "Epoch 38/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5728 - accuracy: 0.7072\n",
            "Epoch 39/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5727 - accuracy: 0.7074\n",
            "Epoch 40/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5727 - accuracy: 0.7075\n",
            "Epoch 41/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5727 - accuracy: 0.7071\n",
            "Epoch 42/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5728 - accuracy: 0.7069\n",
            "Epoch 43/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5726 - accuracy: 0.7079\n",
            "Epoch 44/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5727 - accuracy: 0.7074\n",
            "Epoch 45/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5726 - accuracy: 0.7076\n",
            "Epoch 46/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5726 - accuracy: 0.7076\n",
            "Epoch 47/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5726 - accuracy: 0.7074\n",
            "Epoch 48/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5726 - accuracy: 0.7075\n",
            "Epoch 49/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7079\n",
            "Epoch 50/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7073\n",
            "Epoch 51/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7080\n",
            "Epoch 52/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5726 - accuracy: 0.7074\n",
            "Epoch 53/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7075\n",
            "Epoch 54/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7076\n",
            "Epoch 55/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7076\n",
            "Epoch 56/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5724 - accuracy: 0.7079\n",
            "Epoch 57/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5724 - accuracy: 0.7073\n",
            "Epoch 58/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7075\n",
            "Epoch 59/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5725 - accuracy: 0.7076\n",
            "Epoch 60/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7078\n",
            "Epoch 61/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5724 - accuracy: 0.7077\n",
            "Epoch 62/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7078\n",
            "Epoch 63/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7079\n",
            "Epoch 64/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7080\n",
            "Epoch 65/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7078\n",
            "Epoch 66/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7075\n",
            "Epoch 67/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7077\n",
            "Epoch 68/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7077\n",
            "Epoch 69/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7081\n",
            "Epoch 70/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7079\n",
            "Epoch 71/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5723 - accuracy: 0.7073\n",
            "Epoch 72/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7076\n",
            "Epoch 73/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7078\n",
            "Epoch 74/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7076\n",
            "Epoch 75/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7075\n",
            "Epoch 76/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5722 - accuracy: 0.7079\n",
            "Epoch 77/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7075\n",
            "Epoch 78/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7080\n",
            "Epoch 79/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7082\n",
            "Epoch 80/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7078\n",
            "Epoch 81/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7079\n",
            "Epoch 82/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7079\n",
            "Epoch 83/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7081\n",
            "Epoch 84/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7077\n",
            "Epoch 85/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7081\n",
            "Epoch 86/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7077\n",
            "Epoch 87/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5721 - accuracy: 0.7075\n",
            "Epoch 88/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7081\n",
            "Epoch 89/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7077\n",
            "Epoch 90/100\n",
            "152660/152660 [==============================] - 2s 11us/step - loss: 0.5720 - accuracy: 0.7076\n",
            "Epoch 91/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5719 - accuracy: 0.7078\n",
            "Epoch 92/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7082\n",
            "Epoch 93/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5719 - accuracy: 0.7079\n",
            "Epoch 94/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5719 - accuracy: 0.7072\n",
            "Epoch 95/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7076\n",
            "Epoch 96/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7078\n",
            "Epoch 97/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7074\n",
            "Epoch 98/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5720 - accuracy: 0.7076\n",
            "Epoch 99/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5719 - accuracy: 0.7076\n",
            "Epoch 100/100\n",
            "152660/152660 [==============================] - 2s 10us/step - loss: 0.5719 - accuracy: 0.7077\n",
            "Epoch 1/100\n",
            "57248/57248 [==============================] - 1s 23us/step - loss: 0.6655 - accuracy: 0.6198\n",
            "Epoch 2/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.6459 - accuracy: 0.6496\n",
            "Epoch 3/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.6294 - accuracy: 0.6619\n",
            "Epoch 4/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.6122 - accuracy: 0.6685\n",
            "Epoch 5/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5963 - accuracy: 0.6788\n",
            "Epoch 6/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5860 - accuracy: 0.6936\n",
            "Epoch 7/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5796 - accuracy: 0.7011\n",
            "Epoch 8/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5777 - accuracy: 0.7043\n",
            "Epoch 9/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5772 - accuracy: 0.7030\n",
            "Epoch 10/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5765 - accuracy: 0.7058\n",
            "Epoch 11/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5763 - accuracy: 0.7059\n",
            "Epoch 12/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5764 - accuracy: 0.7040\n",
            "Epoch 13/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5760 - accuracy: 0.7057\n",
            "Epoch 14/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5752 - accuracy: 0.7064\n",
            "Epoch 15/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5754 - accuracy: 0.7046\n",
            "Epoch 16/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5751 - accuracy: 0.7059\n",
            "Epoch 17/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5746 - accuracy: 0.7061\n",
            "Epoch 18/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5748 - accuracy: 0.7059\n",
            "Epoch 19/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5743 - accuracy: 0.7068\n",
            "Epoch 20/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5747 - accuracy: 0.7061\n",
            "Epoch 21/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5744 - accuracy: 0.7058\n",
            "Epoch 22/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5737 - accuracy: 0.7067\n",
            "Epoch 23/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5741 - accuracy: 0.7070\n",
            "Epoch 24/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5740 - accuracy: 0.7079\n",
            "Epoch 25/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5736 - accuracy: 0.7082\n",
            "Epoch 26/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5739 - accuracy: 0.7072\n",
            "Epoch 27/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5736 - accuracy: 0.7078\n",
            "Epoch 28/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5733 - accuracy: 0.7077\n",
            "Epoch 29/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5734 - accuracy: 0.7078\n",
            "Epoch 30/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5733 - accuracy: 0.7073\n",
            "Epoch 31/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5736 - accuracy: 0.7069\n",
            "Epoch 32/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5729 - accuracy: 0.7082\n",
            "Epoch 33/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5730 - accuracy: 0.7088\n",
            "Epoch 34/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5731 - accuracy: 0.7075\n",
            "Epoch 35/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5729 - accuracy: 0.7076\n",
            "Epoch 36/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5729 - accuracy: 0.7074\n",
            "Epoch 37/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7090\n",
            "Epoch 38/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5729 - accuracy: 0.7076\n",
            "Epoch 39/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5727 - accuracy: 0.7087\n",
            "Epoch 40/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5726 - accuracy: 0.7080\n",
            "Epoch 41/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5726 - accuracy: 0.7073\n",
            "Epoch 42/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5726 - accuracy: 0.7081\n",
            "Epoch 43/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5725 - accuracy: 0.7082\n",
            "Epoch 44/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5726 - accuracy: 0.7079\n",
            "Epoch 45/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5723 - accuracy: 0.7082\n",
            "Epoch 46/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5723 - accuracy: 0.7089\n",
            "Epoch 47/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7091\n",
            "Epoch 48/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7082\n",
            "Epoch 49/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5721 - accuracy: 0.7080\n",
            "Epoch 50/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7088\n",
            "Epoch 51/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5720 - accuracy: 0.7083\n",
            "Epoch 52/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7089\n",
            "Epoch 53/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5720 - accuracy: 0.7081\n",
            "Epoch 54/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7084\n",
            "Epoch 55/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7086\n",
            "Epoch 56/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5718 - accuracy: 0.7086\n",
            "Epoch 57/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7083\n",
            "Epoch 58/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5720 - accuracy: 0.7084\n",
            "Epoch 59/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5718 - accuracy: 0.7082\n",
            "Epoch 60/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5717 - accuracy: 0.7077\n",
            "Epoch 61/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7092\n",
            "Epoch 62/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7083\n",
            "Epoch 63/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7087\n",
            "Epoch 64/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7088\n",
            "Epoch 65/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7084\n",
            "Epoch 66/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7091\n",
            "Epoch 67/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7084\n",
            "Epoch 68/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5715 - accuracy: 0.7083\n",
            "Epoch 69/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5715 - accuracy: 0.7084\n",
            "Epoch 70/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7089\n",
            "Epoch 71/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7082\n",
            "Epoch 72/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7080\n",
            "Epoch 73/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7080\n",
            "Epoch 74/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7084\n",
            "Epoch 75/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7086\n",
            "Epoch 76/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7093\n",
            "Epoch 77/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7094\n",
            "Epoch 78/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7085\n",
            "Epoch 79/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5712 - accuracy: 0.7089\n",
            "Epoch 80/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5712 - accuracy: 0.7090\n",
            "Epoch 81/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7086\n",
            "Epoch 82/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7081\n",
            "Epoch 83/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5710 - accuracy: 0.7093\n",
            "Epoch 84/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5711 - accuracy: 0.7094\n",
            "Epoch 85/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7093\n",
            "Epoch 86/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5711 - accuracy: 0.7094\n",
            "Epoch 87/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7084\n",
            "Epoch 88/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7092\n",
            "Epoch 89/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7093\n",
            "Epoch 90/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7081\n",
            "Epoch 91/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7088\n",
            "Epoch 92/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7088\n",
            "Epoch 93/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7095\n",
            "Epoch 94/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7101\n",
            "Epoch 95/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7084\n",
            "Epoch 96/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5709 - accuracy: 0.7092\n",
            "Epoch 97/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7097\n",
            "Epoch 98/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7086\n",
            "Epoch 99/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5708 - accuracy: 0.7094\n",
            "Epoch 100/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7093\n",
            "19083/19083 [==============================] - 0s 20us/step\n",
            "Epoch 1/100\n",
            "57248/57248 [==============================] - 1s 23us/step - loss: 0.6660 - accuracy: 0.6227\n",
            "Epoch 2/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.6457 - accuracy: 0.6517\n",
            "Epoch 3/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.6308 - accuracy: 0.6600\n",
            "Epoch 4/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.6129 - accuracy: 0.6745\n",
            "Epoch 5/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5970 - accuracy: 0.6856\n",
            "Epoch 6/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5859 - accuracy: 0.6978\n",
            "Epoch 7/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5806 - accuracy: 0.7031\n",
            "Epoch 8/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5769 - accuracy: 0.7060\n",
            "Epoch 9/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5761 - accuracy: 0.7075\n",
            "Epoch 10/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5762 - accuracy: 0.7066\n",
            "Epoch 11/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5754 - accuracy: 0.7070\n",
            "Epoch 12/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5750 - accuracy: 0.7080\n",
            "Epoch 13/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5750 - accuracy: 0.7081\n",
            "Epoch 14/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5747 - accuracy: 0.7087\n",
            "Epoch 15/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5747 - accuracy: 0.7081\n",
            "Epoch 16/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5741 - accuracy: 0.7078\n",
            "Epoch 17/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5745 - accuracy: 0.7085\n",
            "Epoch 18/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5742 - accuracy: 0.7091\n",
            "Epoch 19/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5739 - accuracy: 0.7082\n",
            "Epoch 20/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5739 - accuracy: 0.7079\n",
            "Epoch 21/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5736 - accuracy: 0.7094\n",
            "Epoch 22/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5738 - accuracy: 0.7081\n",
            "Epoch 23/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5736 - accuracy: 0.7088\n",
            "Epoch 24/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5740 - accuracy: 0.7077\n",
            "Epoch 25/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5733 - accuracy: 0.7087\n",
            "Epoch 26/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5735 - accuracy: 0.7085\n",
            "Epoch 27/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5731 - accuracy: 0.7089\n",
            "Epoch 28/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5733 - accuracy: 0.7085\n",
            "Epoch 29/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5733 - accuracy: 0.7085\n",
            "Epoch 30/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5730 - accuracy: 0.7097\n",
            "Epoch 31/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5736 - accuracy: 0.7090\n",
            "Epoch 32/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5734 - accuracy: 0.7072\n",
            "Epoch 33/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5732 - accuracy: 0.7083\n",
            "Epoch 34/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5729 - accuracy: 0.7090\n",
            "Epoch 35/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7086\n",
            "Epoch 36/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5730 - accuracy: 0.7091\n",
            "Epoch 37/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5726 - accuracy: 0.7091\n",
            "Epoch 38/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5730 - accuracy: 0.7097\n",
            "Epoch 39/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5729 - accuracy: 0.7078\n",
            "Epoch 40/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5727 - accuracy: 0.7094\n",
            "Epoch 41/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5729 - accuracy: 0.7093\n",
            "Epoch 42/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5723 - accuracy: 0.7095\n",
            "Epoch 43/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7098\n",
            "Epoch 44/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5726 - accuracy: 0.7090\n",
            "Epoch 45/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5725 - accuracy: 0.7093\n",
            "Epoch 46/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5725 - accuracy: 0.7095\n",
            "Epoch 47/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5727 - accuracy: 0.7090\n",
            "Epoch 48/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5727 - accuracy: 0.7086\n",
            "Epoch 49/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5725 - accuracy: 0.7092\n",
            "Epoch 50/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5723 - accuracy: 0.7096\n",
            "Epoch 51/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5721 - accuracy: 0.7092\n",
            "Epoch 52/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7092\n",
            "Epoch 53/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7100\n",
            "Epoch 54/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7086\n",
            "Epoch 55/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5722 - accuracy: 0.7095\n",
            "Epoch 56/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5720 - accuracy: 0.7094\n",
            "Epoch 57/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5721 - accuracy: 0.7099\n",
            "Epoch 58/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5722 - accuracy: 0.7098\n",
            "Epoch 59/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5720 - accuracy: 0.7095\n",
            "Epoch 60/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5721 - accuracy: 0.7093\n",
            "Epoch 61/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5720 - accuracy: 0.7101\n",
            "Epoch 62/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7094\n",
            "Epoch 63/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5721 - accuracy: 0.7093\n",
            "Epoch 64/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7094\n",
            "Epoch 65/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7094\n",
            "Epoch 66/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5720 - accuracy: 0.7095\n",
            "Epoch 67/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7101\n",
            "Epoch 68/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7097\n",
            "Epoch 69/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5720 - accuracy: 0.7099\n",
            "Epoch 70/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7100\n",
            "Epoch 71/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5718 - accuracy: 0.7096\n",
            "Epoch 72/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7090\n",
            "Epoch 73/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5720 - accuracy: 0.7092\n",
            "Epoch 74/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7100\n",
            "Epoch 75/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7094\n",
            "Epoch 76/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7108\n",
            "Epoch 77/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5720 - accuracy: 0.7097\n",
            "Epoch 78/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7105\n",
            "Epoch 79/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7095\n",
            "Epoch 80/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5717 - accuracy: 0.7096\n",
            "Epoch 81/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7101\n",
            "Epoch 82/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5715 - accuracy: 0.7104\n",
            "Epoch 83/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5714 - accuracy: 0.7093\n",
            "Epoch 84/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7102\n",
            "Epoch 85/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7102\n",
            "Epoch 86/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5715 - accuracy: 0.7107\n",
            "Epoch 87/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7095\n",
            "Epoch 88/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7097\n",
            "Epoch 89/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5717 - accuracy: 0.7095\n",
            "Epoch 90/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5712 - accuracy: 0.7108\n",
            "Epoch 91/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7099\n",
            "Epoch 92/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5712 - accuracy: 0.7105\n",
            "Epoch 93/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7105\n",
            "Epoch 94/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5714 - accuracy: 0.7102\n",
            "Epoch 95/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5712 - accuracy: 0.7110\n",
            "Epoch 96/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5713 - accuracy: 0.7097\n",
            "Epoch 97/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7103\n",
            "Epoch 98/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7103\n",
            "Epoch 99/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7106\n",
            "Epoch 100/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7101\n",
            "19083/19083 [==============================] - 0s 22us/step\n",
            "Epoch 1/100\n",
            "57248/57248 [==============================] - 1s 24us/step - loss: 0.6638 - accuracy: 0.6190\n",
            "Epoch 2/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.6441 - accuracy: 0.6518\n",
            "Epoch 3/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.6272 - accuracy: 0.6608\n",
            "Epoch 4/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.6097 - accuracy: 0.6715\n",
            "Epoch 5/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5952 - accuracy: 0.6864\n",
            "Epoch 6/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5836 - accuracy: 0.6990\n",
            "Epoch 7/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5774 - accuracy: 0.7048\n",
            "Epoch 8/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5762 - accuracy: 0.7040\n",
            "Epoch 9/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5752 - accuracy: 0.7053\n",
            "Epoch 10/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5747 - accuracy: 0.7066\n",
            "Epoch 11/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5747 - accuracy: 0.7064\n",
            "Epoch 12/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5746 - accuracy: 0.7058\n",
            "Epoch 13/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5741 - accuracy: 0.7073\n",
            "Epoch 14/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5742 - accuracy: 0.7069\n",
            "Epoch 15/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5743 - accuracy: 0.7067\n",
            "Epoch 16/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5734 - accuracy: 0.7077\n",
            "Epoch 17/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5738 - accuracy: 0.7070\n",
            "Epoch 18/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5735 - accuracy: 0.7074\n",
            "Epoch 19/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5734 - accuracy: 0.7076\n",
            "Epoch 20/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5736 - accuracy: 0.7072\n",
            "Epoch 21/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5730 - accuracy: 0.7079\n",
            "Epoch 22/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5732 - accuracy: 0.7069\n",
            "Epoch 23/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5729 - accuracy: 0.7076\n",
            "Epoch 24/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7077\n",
            "Epoch 25/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5729 - accuracy: 0.7073\n",
            "Epoch 26/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5730 - accuracy: 0.7078\n",
            "Epoch 27/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7074\n",
            "Epoch 28/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5726 - accuracy: 0.7076\n",
            "Epoch 29/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7077\n",
            "Epoch 30/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7085\n",
            "Epoch 31/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7080\n",
            "Epoch 32/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5726 - accuracy: 0.7078\n",
            "Epoch 33/100\n",
            "57248/57248 [==============================] - 1s 10us/step - loss: 0.5726 - accuracy: 0.7079\n",
            "Epoch 34/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5728 - accuracy: 0.7090\n",
            "Epoch 35/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7085\n",
            "Epoch 36/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5725 - accuracy: 0.7074\n",
            "Epoch 37/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7081\n",
            "Epoch 38/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5723 - accuracy: 0.7072\n",
            "Epoch 39/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7073\n",
            "Epoch 40/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5723 - accuracy: 0.7079\n",
            "Epoch 41/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5722 - accuracy: 0.7074\n",
            "Epoch 42/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7084\n",
            "Epoch 43/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7083\n",
            "Epoch 44/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7082\n",
            "Epoch 45/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7078\n",
            "Epoch 46/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7085\n",
            "Epoch 47/100\n",
            "57248/57248 [==============================] - 1s 12us/step - loss: 0.5720 - accuracy: 0.7084\n",
            "Epoch 48/100\n",
            "57248/57248 [==============================] - 1s 12us/step - loss: 0.5720 - accuracy: 0.7083\n",
            "Epoch 49/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7089\n",
            "Epoch 50/100\n",
            "57248/57248 [==============================] - 1s 12us/step - loss: 0.5717 - accuracy: 0.7092\n",
            "Epoch 51/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7088\n",
            "Epoch 52/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7090\n",
            "Epoch 53/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5715 - accuracy: 0.7080\n",
            "Epoch 54/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7088\n",
            "Epoch 55/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5715 - accuracy: 0.7079\n",
            "Epoch 56/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7083\n",
            "Epoch 57/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7090\n",
            "Epoch 58/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5712 - accuracy: 0.7090\n",
            "Epoch 59/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7083\n",
            "Epoch 60/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7096\n",
            "Epoch 61/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7091\n",
            "Epoch 62/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7080\n",
            "Epoch 63/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7084\n",
            "Epoch 64/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7089\n",
            "Epoch 65/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7088\n",
            "Epoch 66/100\n",
            "57248/57248 [==============================] - 1s 12us/step - loss: 0.5711 - accuracy: 0.7086\n",
            "Epoch 67/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5712 - accuracy: 0.7091\n",
            "Epoch 68/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7084\n",
            "Epoch 69/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7086\n",
            "Epoch 70/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7088\n",
            "Epoch 71/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7087\n",
            "Epoch 72/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7097\n",
            "Epoch 73/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7094\n",
            "Epoch 74/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7096\n",
            "Epoch 75/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7097\n",
            "Epoch 76/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7086\n",
            "Epoch 77/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7090\n",
            "Epoch 78/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7090\n",
            "Epoch 79/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7091\n",
            "Epoch 80/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7091\n",
            "Epoch 81/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7104\n",
            "Epoch 82/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5709 - accuracy: 0.7090\n",
            "Epoch 83/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7088\n",
            "Epoch 84/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7086\n",
            "Epoch 85/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7099\n",
            "Epoch 86/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7099\n",
            "Epoch 87/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5705 - accuracy: 0.7098\n",
            "Epoch 88/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7095\n",
            "Epoch 89/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7091\n",
            "Epoch 90/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7097\n",
            "Epoch 91/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7086\n",
            "Epoch 92/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7095\n",
            "Epoch 93/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7092\n",
            "Epoch 94/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5703 - accuracy: 0.7099\n",
            "Epoch 95/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5705 - accuracy: 0.7090\n",
            "Epoch 96/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7093\n",
            "Epoch 97/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5705 - accuracy: 0.7092\n",
            "Epoch 98/100\n",
            "57248/57248 [==============================] - 1s 12us/step - loss: 0.5703 - accuracy: 0.7095\n",
            "Epoch 99/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7101\n",
            "Epoch 100/100\n",
            "57248/57248 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7102\n",
            "19083/19083 [==============================] - 0s 23us/step\n",
            "Epoch 1/100\n",
            "57249/57249 [==============================] - 1s 24us/step - loss: 0.6642 - accuracy: 0.6182\n",
            "Epoch 2/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.6460 - accuracy: 0.6534\n",
            "Epoch 3/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.6301 - accuracy: 0.6623\n",
            "Epoch 4/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.6127 - accuracy: 0.6684\n",
            "Epoch 5/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5972 - accuracy: 0.6847\n",
            "Epoch 6/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5848 - accuracy: 0.6959\n",
            "Epoch 7/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5791 - accuracy: 0.7033\n",
            "Epoch 8/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5765 - accuracy: 0.7075\n",
            "Epoch 9/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5754 - accuracy: 0.7071\n",
            "Epoch 10/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5753 - accuracy: 0.7071\n",
            "Epoch 11/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5745 - accuracy: 0.7065\n",
            "Epoch 12/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5744 - accuracy: 0.7080\n",
            "Epoch 13/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5745 - accuracy: 0.7078\n",
            "Epoch 14/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5739 - accuracy: 0.7079\n",
            "Epoch 15/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5734 - accuracy: 0.7096\n",
            "Epoch 16/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5735 - accuracy: 0.7088\n",
            "Epoch 17/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5733 - accuracy: 0.7094\n",
            "Epoch 18/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5731 - accuracy: 0.7089\n",
            "Epoch 19/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5730 - accuracy: 0.7093\n",
            "Epoch 20/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5725 - accuracy: 0.7093\n",
            "Epoch 21/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5729 - accuracy: 0.7093\n",
            "Epoch 22/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5723 - accuracy: 0.7090\n",
            "Epoch 23/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5725 - accuracy: 0.7084\n",
            "Epoch 24/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5725 - accuracy: 0.7093\n",
            "Epoch 25/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5724 - accuracy: 0.7087\n",
            "Epoch 26/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5723 - accuracy: 0.7093\n",
            "Epoch 27/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5721 - accuracy: 0.7095\n",
            "Epoch 28/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5719 - accuracy: 0.7093\n",
            "Epoch 29/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7090\n",
            "Epoch 30/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5720 - accuracy: 0.7096\n",
            "Epoch 31/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5721 - accuracy: 0.7094\n",
            "Epoch 32/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7095\n",
            "Epoch 33/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7101\n",
            "Epoch 34/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7091\n",
            "Epoch 35/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5717 - accuracy: 0.7100\n",
            "Epoch 36/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5718 - accuracy: 0.7099\n",
            "Epoch 37/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5715 - accuracy: 0.7100\n",
            "Epoch 38/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7097\n",
            "Epoch 39/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7111\n",
            "Epoch 40/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7094\n",
            "Epoch 41/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5716 - accuracy: 0.7101\n",
            "Epoch 42/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5716 - accuracy: 0.7095\n",
            "Epoch 43/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7097\n",
            "Epoch 44/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7104\n",
            "Epoch 45/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5714 - accuracy: 0.7101\n",
            "Epoch 46/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7109\n",
            "Epoch 47/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7104\n",
            "Epoch 48/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5710 - accuracy: 0.7100\n",
            "Epoch 49/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5713 - accuracy: 0.7100\n",
            "Epoch 50/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7105\n",
            "Epoch 51/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7106\n",
            "Epoch 52/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5710 - accuracy: 0.7107\n",
            "Epoch 53/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5710 - accuracy: 0.7094\n",
            "Epoch 54/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7099\n",
            "Epoch 55/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5711 - accuracy: 0.7109\n",
            "Epoch 56/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5709 - accuracy: 0.7100\n",
            "Epoch 57/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5708 - accuracy: 0.7101\n",
            "Epoch 58/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7096\n",
            "Epoch 59/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7096\n",
            "Epoch 60/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7097\n",
            "Epoch 61/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7097\n",
            "Epoch 62/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7101\n",
            "Epoch 63/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5707 - accuracy: 0.7107\n",
            "Epoch 64/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7100\n",
            "Epoch 65/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7102\n",
            "Epoch 66/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7103\n",
            "Epoch 67/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7102\n",
            "Epoch 68/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5706 - accuracy: 0.7103\n",
            "Epoch 69/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5705 - accuracy: 0.7100\n",
            "Epoch 70/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5705 - accuracy: 0.7106\n",
            "Epoch 71/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7104\n",
            "Epoch 72/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7103\n",
            "Epoch 73/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7098\n",
            "Epoch 74/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7100\n",
            "Epoch 75/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5706 - accuracy: 0.7109\n",
            "Epoch 76/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5705 - accuracy: 0.7108\n",
            "Epoch 77/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5703 - accuracy: 0.7112\n",
            "Epoch 78/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7105\n",
            "Epoch 79/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7108\n",
            "Epoch 80/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5704 - accuracy: 0.7105\n",
            "Epoch 81/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7108\n",
            "Epoch 82/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5703 - accuracy: 0.7112\n",
            "Epoch 83/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7107\n",
            "Epoch 84/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5701 - accuracy: 0.7101\n",
            "Epoch 85/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7106\n",
            "Epoch 86/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5700 - accuracy: 0.7109\n",
            "Epoch 87/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7104\n",
            "Epoch 88/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5701 - accuracy: 0.7100\n",
            "Epoch 89/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5702 - accuracy: 0.7101\n",
            "Epoch 90/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7115\n",
            "Epoch 91/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7113\n",
            "Epoch 92/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5701 - accuracy: 0.7105\n",
            "Epoch 93/100\n",
            "57249/57249 [==============================] - 1s 12us/step - loss: 0.5702 - accuracy: 0.7115\n",
            "Epoch 94/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5701 - accuracy: 0.7101\n",
            "Epoch 95/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7109\n",
            "Epoch 96/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7118\n",
            "Epoch 97/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7108\n",
            "Epoch 98/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5700 - accuracy: 0.7113\n",
            "Epoch 99/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7110\n",
            "Epoch 100/100\n",
            "57249/57249 [==============================] - 1s 11us/step - loss: 0.5699 - accuracy: 0.7110\n",
            "19082/19082 [==============================] - 0s 26us/step\n",
            "Cross-validation evaluations\n",
            "Results: 70.51% (0.09%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gt9a5Ec6f6pb"
      },
      "source": [
        "# Prediction Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ncGezYHf-8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c21f7ad-a4c0-45c0-ae54-3ae963a26fd7"
      },
      "source": [
        "x = pd.DataFrame({'Scenario': [1,1,1],'Scenario_order' : [0,0,0],'lang': [1,3,5], 'seenOther': [0,0,0],'country_code': [3,3,3]})\n",
        "\n",
        "prediction = pipeline['mlp'].predict(x)\n",
        "prediction "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r3/3 [==============================] - 1s 277ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Re2md7rK_rt6",
        "outputId": "09da1dd7-6328-48dc-a555-c0b551ab6e02"
      },
      "source": [
        "# List of all possibilities\n",
        "x_list = pd.DataFrame(pd.DataFrame(columns=['Scenario','Scenario_order','lang','seenOther','country_code']))\n",
        "for c in range(len(country)):\n",
        "  for l in range(len(lang)):\n",
        "      for so in range(2):\n",
        "        for seen_o in range(2):\n",
        "          for sen in range(3):\n",
        "            x_list = x_list.append({'Scenario': sen,'Scenario_order' : so,'lang': l, 'seenOther': seen_o,'country_code': c}, ignore_index=True)\n",
        "x_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Scenario</th>\n",
              "      <th>Scenario_order</th>\n",
              "      <th>lang</th>\n",
              "      <th>seenOther</th>\n",
              "      <th>country_code</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20155</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20156</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20157</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20158</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20159</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20160 rows  5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Scenario Scenario_order lang seenOther country_code\n",
              "0            0              0    0         0            0\n",
              "1            1              0    0         0            0\n",
              "2            2              0    0         0            0\n",
              "3            0              0    0         1            0\n",
              "4            1              0    0         1            0\n",
              "...        ...            ...  ...       ...          ...\n",
              "20155        1              1    9         0          167\n",
              "20156        2              1    9         0          167\n",
              "20157        0              1    9         1          167\n",
              "20158        1              1    9         1          167\n",
              "20159        2              1    9         1          167\n",
              "\n",
              "[20160 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQeacE0YA9GL",
        "outputId": "49424db4-7a52-4214-94fd-2cdb0b9675dc"
      },
      "source": [
        "prediction = pipeline['mlp'].predict(x_list)\n",
        "prediction\n",
        "zero = pd.DataFrame(pd.DataFrame(columns=['Scenario','Scenario_order','lang','seenOther','country_code']))\n",
        "\n",
        "for x in range(len(prediction)):\n",
        "  if 0 in prediction[x]:\n",
        "    zero = zero.append(x_list.iloc[x])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20160/20160 [==============================] - 0s 4us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNIdeLW8H7nH",
        "outputId": "6510c338-918e-43df-8859-a9488083a86f"
      },
      "source": [
        "zero.reset_index()\n",
        "zero.info()\n",
        "#1123 out of 20160 instances will not interact, only 5.57%"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1123 entries, 0 to 4077\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   Scenario        1123 non-null   object\n",
            " 1   Scenario_order  1123 non-null   object\n",
            " 2   lang            1123 non-null   object\n",
            " 3   seenOther       1123 non-null   object\n",
            " 4   country_code    1123 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 52.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLO_L5ByIndM"
      },
      "source": [
        "# Language and Country keys"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZRv3oXti0pZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cf236b6-0d92-42d0-e61a-86cba39a02d5"
      },
      "source": [
        "lang"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ar': 8,\n",
              " 'de': 0,\n",
              " 'en': 1,\n",
              " 'es': 5,\n",
              " 'fr': 3,\n",
              " 'ja': 9,\n",
              " 'kr': 7,\n",
              " 'pt': 4,\n",
              " 'ru': 6,\n",
              " 'zh': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "til03ThUi3Kj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567aed85-beff-4ef8-caad-8a3964341b0a"
      },
      "source": [
        "country"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AD': 132,\n",
              " 'AE': 77,\n",
              " 'AF': 138,\n",
              " 'AL': 125,\n",
              " 'AM': 80,\n",
              " 'AO': 102,\n",
              " 'AQ': 162,\n",
              " 'AR': 76,\n",
              " 'AT': 25,\n",
              " 'AU': 19,\n",
              " 'AX': 167,\n",
              " 'AZ': 68,\n",
              " 'BA': 101,\n",
              " 'BB': 152,\n",
              " 'BD': 81,\n",
              " 'BE': 22,\n",
              " 'BG': 54,\n",
              " 'BH': 93,\n",
              " 'BJ': 130,\n",
              " 'BN': 148,\n",
              " 'BO': 56,\n",
              " 'BR': 9,\n",
              " 'BS': 82,\n",
              " 'BY': 39,\n",
              " 'CA': 6,\n",
              " 'CD': 134,\n",
              " 'CH': 18,\n",
              " 'CI': 154,\n",
              " 'CL': 17,\n",
              " 'CN': 20,\n",
              " 'CO': 32,\n",
              " 'CR': 59,\n",
              " 'CU': 88,\n",
              " 'CV': 163,\n",
              " 'CY': 121,\n",
              " 'CZ': 26,\n",
              " 'DE': 0,\n",
              " 'DK': 31,\n",
              " 'DM': 164,\n",
              " 'DO': 92,\n",
              " 'DZ': 67,\n",
              " 'EC': 65,\n",
              " 'EE': 8,\n",
              " 'EG': 57,\n",
              " 'ES': 11,\n",
              " 'FI': 29,\n",
              " 'FO': 153,\n",
              " 'FR': 4,\n",
              " 'GB': 1,\n",
              " 'GD': 124,\n",
              " 'GE': 99,\n",
              " 'GF': 140,\n",
              " 'GG': 149,\n",
              " 'GH': 150,\n",
              " 'GI': 159,\n",
              " 'GP': 96,\n",
              " 'GR': 44,\n",
              " 'GT': 13,\n",
              " 'GY': 165,\n",
              " 'HK': 43,\n",
              " 'HN': 95,\n",
              " 'HR': 84,\n",
              " 'HT': 97,\n",
              " 'HU': 14,\n",
              " 'ID': 50,\n",
              " 'IE': 34,\n",
              " 'IL': 61,\n",
              " 'IM': 114,\n",
              " 'IN': 46,\n",
              " 'IQ': 100,\n",
              " 'IR': 64,\n",
              " 'IS': 27,\n",
              " 'IT': 7,\n",
              " 'JE': 137,\n",
              " 'JM': 117,\n",
              " 'JO': 107,\n",
              " 'JP': 38,\n",
              " 'KE': 90,\n",
              " 'KG': 55,\n",
              " 'KH': 112,\n",
              " 'KN': 146,\n",
              " 'KR': 35,\n",
              " 'KW': 110,\n",
              " 'KY': 139,\n",
              " 'KZ': 75,\n",
              " 'LB': 118,\n",
              " 'LC': 151,\n",
              " 'LI': 142,\n",
              " 'LK': 98,\n",
              " 'LR': 119,\n",
              " 'LT': 70,\n",
              " 'LU': 12,\n",
              " 'LV': 48,\n",
              " 'MA': 104,\n",
              " 'MC': 157,\n",
              " 'MD': 87,\n",
              " 'ME': 116,\n",
              " 'MG': 131,\n",
              " 'MK': 120,\n",
              " 'ML': 161,\n",
              " 'MM': 86,\n",
              " 'MN': 141,\n",
              " 'MO': 66,\n",
              " 'MQ': 42,\n",
              " 'MR': 144,\n",
              " 'MT': 73,\n",
              " 'MU': 106,\n",
              " 'MV': 158,\n",
              " 'MW': 147,\n",
              " 'MX': 45,\n",
              " 'MY': 37,\n",
              " 'MZ': 60,\n",
              " 'NC': 69,\n",
              " 'NG': 155,\n",
              " 'NI': 94,\n",
              " 'NL': 52,\n",
              " 'NO': 74,\n",
              " 'NP': 89,\n",
              " 'NZ': 16,\n",
              " 'OM': 133,\n",
              " 'PA': 83,\n",
              " 'PE': 53,\n",
              " 'PF': 128,\n",
              " 'PH': 36,\n",
              " 'PK': 115,\n",
              " 'PL': 23,\n",
              " 'PM': 135,\n",
              " 'PR': 78,\n",
              " 'PS': 143,\n",
              " 'PT': 30,\n",
              " 'PY': 123,\n",
              " 'QA': 85,\n",
              " 'RE': 109,\n",
              " 'RO': 40,\n",
              " 'RS': 15,\n",
              " 'RU': 21,\n",
              " 'SA': 41,\n",
              " 'SC': 113,\n",
              " 'SD': 136,\n",
              " 'SE': 47,\n",
              " 'SG': 58,\n",
              " 'SI': 79,\n",
              " 'SK': 63,\n",
              " 'SM': 160,\n",
              " 'SN': 127,\n",
              " 'SR': 103,\n",
              " 'SV': 105,\n",
              " 'SY': 129,\n",
              " 'TG': 166,\n",
              " 'TH': 28,\n",
              " 'TL': 111,\n",
              " 'TN': 51,\n",
              " 'TR': 2,\n",
              " 'TT': 126,\n",
              " 'TW': 10,\n",
              " 'TZ': 122,\n",
              " 'UA': 24,\n",
              " 'UG': 108,\n",
              " 'US': 3,\n",
              " 'UY': 71,\n",
              " 'UZ': 62,\n",
              " 'VA': 145,\n",
              " 'VE': 72,\n",
              " 'VI': 156,\n",
              " 'VN': 5,\n",
              " 'YT': 91,\n",
              " 'ZA': 49,\n",
              " 'ZM': 33}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFBDRn-Ve2uM"
      },
      "source": [
        "# Other less accurate NNs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V89Ylk9L20S2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "1a6331e6-fd9a-4865-d352-4f68d2edc547"
      },
      "source": [
        "#Basic\n",
        "model = Sequential()\n",
        "model.add(Dense(60, input_dim=5, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(10, activation='sigmoid'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train,y_train,epochs=10, validation_data=(x_val,y_val),batch_size=50)\n",
        "loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (acc*100, loss*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 76330 samples, validate on 76331 samples\n",
            "Epoch 1/10\n",
            "76330/76330 [==============================] - 5s 65us/step - loss: 0.5999 - accuracy: 0.6968 - val_loss: 0.5834 - val_accuracy: 0.7000\n",
            "Epoch 2/10\n",
            "76330/76330 [==============================] - 5s 61us/step - loss: 0.5826 - accuracy: 0.7015 - val_loss: 0.5816 - val_accuracy: 0.6958\n",
            "Epoch 3/10\n",
            "76330/76330 [==============================] - 5s 59us/step - loss: 0.5810 - accuracy: 0.7014 - val_loss: 0.5795 - val_accuracy: 0.7014\n",
            "Epoch 4/10\n",
            "76330/76330 [==============================] - 4s 57us/step - loss: 0.5801 - accuracy: 0.7008 - val_loss: 0.5782 - val_accuracy: 0.7005\n",
            "Epoch 5/10\n",
            "   50/76330 [..............................] - ETA: 7s - loss: 0.6066 - accuracy: 0.6600"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-3979ef2c882c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    894\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0munwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0munwrapped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36munwrapped\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0munwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUF7hbQky_ld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "be8abe78-878b-42f0-f038-e0bbc3ea7ab4"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(24, input_dim=5,kernel_initializer='random_uniform'))\n",
        "\n",
        "model.add(layers.Dense(64,activation=\"relu\",kernel_initializer='random_uniform'))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(.5))\n",
        "model.add(layers.Dense(64, activation=\"relu\",kernel_initializer='random_uniform'))\n",
        "model.add(layers.BatchNormalization())\n",
        "\n",
        "model.add(Dense(1,activation=\"sigmoid\",kernel_initializer='random_uniform'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=3000)\n",
        "# evaluate the keras model\n",
        "_, accuracy = model.evaluate(x_test, y_test)\n",
        "print('Accuracy: %.2f%%' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "76330/76330 [==============================] - 1s 14us/step - loss: 0.6830 - accuracy: 0.5461\n",
            "Epoch 2/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.6530 - accuracy: 0.6186\n",
            "Epoch 3/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.6296 - accuracy: 0.6538\n",
            "Epoch 4/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.6069 - accuracy: 0.6798\n",
            "Epoch 5/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5917 - accuracy: 0.6969\n",
            "Epoch 6/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5865 - accuracy: 0.7000\n",
            "Epoch 7/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5844 - accuracy: 0.7009\n",
            "Epoch 8/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5839 - accuracy: 0.7007\n",
            "Epoch 9/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5837 - accuracy: 0.7004\n",
            "Epoch 10/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5831 - accuracy: 0.7007\n",
            "Epoch 11/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5824 - accuracy: 0.7014\n",
            "Epoch 12/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5825 - accuracy: 0.7019\n",
            "Epoch 13/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5819 - accuracy: 0.7019\n",
            "Epoch 14/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5810 - accuracy: 0.7021\n",
            "Epoch 15/100\n",
            "76330/76330 [==============================] - 1s 7us/step - loss: 0.5813 - accuracy: 0.7011\n",
            "Epoch 16/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5816 - accuracy: 0.7008\n",
            "Epoch 17/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5815 - accuracy: 0.7016\n",
            "Epoch 18/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5815 - accuracy: 0.7010\n",
            "Epoch 19/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5810 - accuracy: 0.7010\n",
            "Epoch 20/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5810 - accuracy: 0.7018\n",
            "Epoch 21/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5809 - accuracy: 0.7009\n",
            "Epoch 22/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5808 - accuracy: 0.7011\n",
            "Epoch 23/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5808 - accuracy: 0.7010\n",
            "Epoch 24/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5808 - accuracy: 0.7018\n",
            "Epoch 25/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5808 - accuracy: 0.7018\n",
            "Epoch 26/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5804 - accuracy: 0.7012\n",
            "Epoch 27/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5809 - accuracy: 0.7012\n",
            "Epoch 28/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5809 - accuracy: 0.7009\n",
            "Epoch 29/100\n",
            "76330/76330 [==============================] - 0s 6us/step - loss: 0.5808 - accuracy: 0.7008\n",
            "Epoch 30/100\n",
            "21000/76330 [=======>......................] - ETA: 0s - loss: 0.5815 - accuracy: 0.7029"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-380ef3cb0a06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# fit the keras model on the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;31m# evaluate the keras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gblmfbMdiwNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8edc8aea-fe2d-409e-ea06-8ec73b770fa5"
      },
      "source": [
        "def create_model():\n",
        "  my_init = keras.initializers.glorot_uniform(seed=1)\n",
        "  model = Sequential()\n",
        "  model.add(Dense(140,input_dim=5, activation='relu',kernel_initializer=my_init))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(70, activation='relu',kernel_initializer=my_init))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(1, activation='sigmoid',kernel_initializer=my_init))\n",
        "  model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "estimators = []\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_model, epochs=100, batch_size=1000, verbose=1)))\n",
        "pipeline = Pipeline(estimators)\n",
        "kfold = StratifiedKFold(n_splits=2, shuffle=True)\n",
        "results = cross_val_score(pipeline, x_train, y_train, cv=kfold)\n",
        "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "38412/38412 [==============================] - 3s 66us/step - loss: 0.6454 - accuracy: 0.6385\n",
            "Epoch 2/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5918 - accuracy: 0.6901\n",
            "Epoch 3/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5818 - accuracy: 0.6985\n",
            "Epoch 4/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5795 - accuracy: 0.7009\n",
            "Epoch 5/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5796 - accuracy: 0.7022\n",
            "Epoch 6/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5782 - accuracy: 0.7035\n",
            "Epoch 7/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5772 - accuracy: 0.7046\n",
            "Epoch 8/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5769 - accuracy: 0.7052\n",
            "Epoch 9/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5773 - accuracy: 0.7039\n",
            "Epoch 10/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5760 - accuracy: 0.7040\n",
            "Epoch 11/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5752 - accuracy: 0.7071\n",
            "Epoch 12/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5755 - accuracy: 0.7055\n",
            "Epoch 13/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5750 - accuracy: 0.7055\n",
            "Epoch 14/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5758 - accuracy: 0.7034\n",
            "Epoch 15/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5743 - accuracy: 0.7064\n",
            "Epoch 16/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5749 - accuracy: 0.7055\n",
            "Epoch 17/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5737 - accuracy: 0.7060\n",
            "Epoch 18/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5735 - accuracy: 0.7069\n",
            "Epoch 19/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5738 - accuracy: 0.7063\n",
            "Epoch 20/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5733 - accuracy: 0.7078\n",
            "Epoch 21/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5734 - accuracy: 0.7069\n",
            "Epoch 22/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5732 - accuracy: 0.7067\n",
            "Epoch 23/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5729 - accuracy: 0.7075\n",
            "Epoch 24/100\n",
            "38412/38412 [==============================] - 1s 16us/step - loss: 0.5732 - accuracy: 0.7059\n",
            "Epoch 25/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5729 - accuracy: 0.7064\n",
            "Epoch 26/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5724 - accuracy: 0.7082\n",
            "Epoch 27/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5724 - accuracy: 0.7064\n",
            "Epoch 28/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5726 - accuracy: 0.7077\n",
            "Epoch 29/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5723 - accuracy: 0.7064\n",
            "Epoch 30/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5724 - accuracy: 0.7079\n",
            "Epoch 31/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5722 - accuracy: 0.7083\n",
            "Epoch 32/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5719 - accuracy: 0.7063\n",
            "Epoch 33/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5720 - accuracy: 0.7066\n",
            "Epoch 34/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5718 - accuracy: 0.7086\n",
            "Epoch 35/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5725 - accuracy: 0.7077\n",
            "Epoch 36/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5722 - accuracy: 0.7077\n",
            "Epoch 37/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5719 - accuracy: 0.7074\n",
            "Epoch 38/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5716 - accuracy: 0.7075\n",
            "Epoch 39/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5718 - accuracy: 0.7075\n",
            "Epoch 40/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5716 - accuracy: 0.7079\n",
            "Epoch 41/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5711 - accuracy: 0.7078\n",
            "Epoch 42/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5718 - accuracy: 0.7082\n",
            "Epoch 43/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5713 - accuracy: 0.7079\n",
            "Epoch 44/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5714 - accuracy: 0.7074\n",
            "Epoch 45/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5713 - accuracy: 0.7082\n",
            "Epoch 46/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5711 - accuracy: 0.7078\n",
            "Epoch 47/100\n",
            "38412/38412 [==============================] - 1s 16us/step - loss: 0.5710 - accuracy: 0.7067\n",
            "Epoch 48/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5714 - accuracy: 0.7077\n",
            "Epoch 49/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5711 - accuracy: 0.7088\n",
            "Epoch 50/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5709 - accuracy: 0.7092\n",
            "Epoch 51/100\n",
            "38412/38412 [==============================] - 1s 16us/step - loss: 0.5710 - accuracy: 0.7083\n",
            "Epoch 52/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5712 - accuracy: 0.7080\n",
            "Epoch 53/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5707 - accuracy: 0.7099\n",
            "Epoch 54/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5708 - accuracy: 0.7082\n",
            "Epoch 55/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5707 - accuracy: 0.7092\n",
            "Epoch 56/100\n",
            "38412/38412 [==============================] - 1s 16us/step - loss: 0.5707 - accuracy: 0.7078\n",
            "Epoch 57/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5710 - accuracy: 0.7091\n",
            "Epoch 58/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5708 - accuracy: 0.7087\n",
            "Epoch 59/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5705 - accuracy: 0.7091\n",
            "Epoch 60/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5707 - accuracy: 0.7079\n",
            "Epoch 61/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5709 - accuracy: 0.7085\n",
            "Epoch 62/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5708 - accuracy: 0.7086\n",
            "Epoch 63/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5706 - accuracy: 0.7075\n",
            "Epoch 64/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5701 - accuracy: 0.7083\n",
            "Epoch 65/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5705 - accuracy: 0.7090\n",
            "Epoch 66/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5707 - accuracy: 0.7098\n",
            "Epoch 67/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5704 - accuracy: 0.7087\n",
            "Epoch 68/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5705 - accuracy: 0.7092\n",
            "Epoch 69/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5702 - accuracy: 0.7081\n",
            "Epoch 70/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5703 - accuracy: 0.7079\n",
            "Epoch 71/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5700 - accuracy: 0.7086\n",
            "Epoch 72/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5704 - accuracy: 0.7084\n",
            "Epoch 73/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5700 - accuracy: 0.7077\n",
            "Epoch 74/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5699 - accuracy: 0.7078\n",
            "Epoch 75/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5699 - accuracy: 0.7094\n",
            "Epoch 76/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5706 - accuracy: 0.7102\n",
            "Epoch 77/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5701 - accuracy: 0.7081\n",
            "Epoch 78/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5700 - accuracy: 0.7099\n",
            "Epoch 79/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5704 - accuracy: 0.7083\n",
            "Epoch 80/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5701 - accuracy: 0.7087\n",
            "Epoch 81/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5700 - accuracy: 0.7082\n",
            "Epoch 82/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5702 - accuracy: 0.7089\n",
            "Epoch 83/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5699 - accuracy: 0.7102\n",
            "Epoch 84/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5700 - accuracy: 0.7091\n",
            "Epoch 85/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5700 - accuracy: 0.7074\n",
            "Epoch 86/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5696 - accuracy: 0.7085\n",
            "Epoch 87/100\n",
            "38412/38412 [==============================] - 1s 16us/step - loss: 0.5704 - accuracy: 0.7080\n",
            "Epoch 88/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5699 - accuracy: 0.7084\n",
            "Epoch 89/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5696 - accuracy: 0.7098\n",
            "Epoch 90/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5699 - accuracy: 0.7099\n",
            "Epoch 91/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5698 - accuracy: 0.7096\n",
            "Epoch 92/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5698 - accuracy: 0.7099\n",
            "Epoch 93/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5695 - accuracy: 0.7104\n",
            "Epoch 94/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5696 - accuracy: 0.7089\n",
            "Epoch 95/100\n",
            "38412/38412 [==============================] - 1s 14us/step - loss: 0.5699 - accuracy: 0.7085\n",
            "Epoch 96/100\n",
            "38412/38412 [==============================] - 1s 16us/step - loss: 0.5696 - accuracy: 0.7087\n",
            "Epoch 97/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5697 - accuracy: 0.7087\n",
            "Epoch 98/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5699 - accuracy: 0.7087\n",
            "Epoch 99/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5695 - accuracy: 0.7102\n",
            "Epoch 100/100\n",
            "38412/38412 [==============================] - 1s 15us/step - loss: 0.5697 - accuracy: 0.7086\n",
            "38413/38413 [==============================] - 2s 53us/step\n",
            "Epoch 1/100\n",
            "38413/38413 [==============================] - 3s 67us/step - loss: 0.6461 - accuracy: 0.6424\n",
            "Epoch 2/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5934 - accuracy: 0.6857\n",
            "Epoch 3/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5833 - accuracy: 0.6988\n",
            "Epoch 4/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5801 - accuracy: 0.7004\n",
            "Epoch 5/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5806 - accuracy: 0.7019\n",
            "Epoch 6/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5790 - accuracy: 0.7042\n",
            "Epoch 7/100\n",
            "38413/38413 [==============================] - 1s 14us/step - loss: 0.5791 - accuracy: 0.7017\n",
            "Epoch 8/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5788 - accuracy: 0.7015\n",
            "Epoch 9/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5779 - accuracy: 0.7042\n",
            "Epoch 10/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5771 - accuracy: 0.7043\n",
            "Epoch 11/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5768 - accuracy: 0.7049\n",
            "Epoch 12/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5768 - accuracy: 0.7055\n",
            "Epoch 13/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5762 - accuracy: 0.7044\n",
            "Epoch 14/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5758 - accuracy: 0.7063\n",
            "Epoch 15/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5764 - accuracy: 0.7039\n",
            "Epoch 16/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5760 - accuracy: 0.7052\n",
            "Epoch 17/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5753 - accuracy: 0.7072\n",
            "Epoch 18/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5754 - accuracy: 0.7042\n",
            "Epoch 19/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5743 - accuracy: 0.7043\n",
            "Epoch 20/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5747 - accuracy: 0.7052\n",
            "Epoch 21/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5748 - accuracy: 0.7071\n",
            "Epoch 22/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5750 - accuracy: 0.7043\n",
            "Epoch 23/100\n",
            "38413/38413 [==============================] - 1s 17us/step - loss: 0.5745 - accuracy: 0.7067\n",
            "Epoch 24/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5741 - accuracy: 0.7065\n",
            "Epoch 25/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5746 - accuracy: 0.7066\n",
            "Epoch 26/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5744 - accuracy: 0.7063\n",
            "Epoch 27/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5742 - accuracy: 0.7070\n",
            "Epoch 28/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5742 - accuracy: 0.7078\n",
            "Epoch 29/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5741 - accuracy: 0.7063\n",
            "Epoch 30/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5735 - accuracy: 0.7066\n",
            "Epoch 31/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5738 - accuracy: 0.7061\n",
            "Epoch 32/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5732 - accuracy: 0.7067\n",
            "Epoch 33/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5739 - accuracy: 0.7071\n",
            "Epoch 34/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5734 - accuracy: 0.7067\n",
            "Epoch 35/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5731 - accuracy: 0.7069\n",
            "Epoch 36/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5735 - accuracy: 0.7083\n",
            "Epoch 37/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5730 - accuracy: 0.7079\n",
            "Epoch 38/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5729 - accuracy: 0.7068\n",
            "Epoch 39/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5729 - accuracy: 0.7071\n",
            "Epoch 40/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5727 - accuracy: 0.7080\n",
            "Epoch 41/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5732 - accuracy: 0.7086\n",
            "Epoch 42/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5727 - accuracy: 0.7079\n",
            "Epoch 43/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5730 - accuracy: 0.7075\n",
            "Epoch 44/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5725 - accuracy: 0.7067\n",
            "Epoch 45/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5728 - accuracy: 0.7074\n",
            "Epoch 46/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5730 - accuracy: 0.7081\n",
            "Epoch 47/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5728 - accuracy: 0.7076\n",
            "Epoch 48/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5725 - accuracy: 0.7073\n",
            "Epoch 49/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5724 - accuracy: 0.7089\n",
            "Epoch 50/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5727 - accuracy: 0.7066\n",
            "Epoch 51/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5725 - accuracy: 0.7075\n",
            "Epoch 52/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5727 - accuracy: 0.7068\n",
            "Epoch 53/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5724 - accuracy: 0.7080\n",
            "Epoch 54/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5724 - accuracy: 0.7082\n",
            "Epoch 55/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5717 - accuracy: 0.7092\n",
            "Epoch 56/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5720 - accuracy: 0.7096\n",
            "Epoch 57/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5720 - accuracy: 0.7078\n",
            "Epoch 58/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5723 - accuracy: 0.7090\n",
            "Epoch 59/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5719 - accuracy: 0.7076\n",
            "Epoch 60/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5722 - accuracy: 0.7074\n",
            "Epoch 61/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5717 - accuracy: 0.7084\n",
            "Epoch 62/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5718 - accuracy: 0.7091\n",
            "Epoch 63/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5720 - accuracy: 0.7084\n",
            "Epoch 64/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5721 - accuracy: 0.7082\n",
            "Epoch 65/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5720 - accuracy: 0.7092\n",
            "Epoch 66/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5719 - accuracy: 0.7079\n",
            "Epoch 67/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5713 - accuracy: 0.7077\n",
            "Epoch 68/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5721 - accuracy: 0.7075\n",
            "Epoch 69/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5716 - accuracy: 0.7094\n",
            "Epoch 70/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5716 - accuracy: 0.7081\n",
            "Epoch 71/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5720 - accuracy: 0.7076\n",
            "Epoch 72/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5717 - accuracy: 0.7083\n",
            "Epoch 73/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5715 - accuracy: 0.7080\n",
            "Epoch 74/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5718 - accuracy: 0.7084\n",
            "Epoch 75/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5715 - accuracy: 0.7072\n",
            "Epoch 76/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5715 - accuracy: 0.7087\n",
            "Epoch 77/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5717 - accuracy: 0.7084\n",
            "Epoch 78/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5716 - accuracy: 0.7086\n",
            "Epoch 79/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5715 - accuracy: 0.7086\n",
            "Epoch 80/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5715 - accuracy: 0.7096\n",
            "Epoch 81/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5715 - accuracy: 0.7106\n",
            "Epoch 82/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5710 - accuracy: 0.7085\n",
            "Epoch 83/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5710 - accuracy: 0.7092\n",
            "Epoch 84/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5713 - accuracy: 0.7080\n",
            "Epoch 85/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5709 - accuracy: 0.7078\n",
            "Epoch 86/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5717 - accuracy: 0.7073\n",
            "Epoch 87/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5714 - accuracy: 0.7085\n",
            "Epoch 88/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5712 - accuracy: 0.7088\n",
            "Epoch 89/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5710 - accuracy: 0.7078\n",
            "Epoch 90/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5709 - accuracy: 0.7074\n",
            "Epoch 91/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5713 - accuracy: 0.7094\n",
            "Epoch 92/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5711 - accuracy: 0.7098\n",
            "Epoch 93/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5708 - accuracy: 0.7089\n",
            "Epoch 94/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5710 - accuracy: 0.7086\n",
            "Epoch 95/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5709 - accuracy: 0.7083\n",
            "Epoch 96/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5708 - accuracy: 0.7088\n",
            "Epoch 97/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5711 - accuracy: 0.7086\n",
            "Epoch 98/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5711 - accuracy: 0.7099\n",
            "Epoch 99/100\n",
            "38413/38413 [==============================] - 1s 16us/step - loss: 0.5709 - accuracy: 0.7080\n",
            "Epoch 100/100\n",
            "38413/38413 [==============================] - 1s 15us/step - loss: 0.5710 - accuracy: 0.7081\n",
            "38412/38412 [==============================] - 2s 54us/step\n",
            "Results: 70.52% (0.03%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q2EuIaBs5up"
      },
      "source": [
        "# Epochs vs Batch Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHTgXju1bcxa"
      },
      "source": [
        "def buildModel():\n",
        "  model = Sequential()\n",
        "  model.add(Dense(60, input_dim=5, activation='relu'))\n",
        "  model.add(Dense(40, activation='relu'))\n",
        "  model.add(Dense(10, activation='sigmoid'))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZW3TBSLtrtZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9d8b81-718c-46e3-dd4c-59b0413874c9"
      },
      "source": [
        "acc = dict()\n",
        "for batch in range(1,15): #batch size \n",
        "  for epoch in range(1,15): #epochs\n",
        "    print(\"Epochs: {0} \\t Batch Size: {1}\".format(10*epoch,16*batch))\n",
        "    model = buildModel()\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(x_train, y_train, epochs=(10*epoch), batch_size=(16*batch),verbose=0)\n",
        "    loss, accuracy = model.evaluate(x_test, y_test,verbose=0)\n",
        "    key = \"epochs{0}batch{1}\".format(10*epoch,16*batch)\n",
        "    acc[key] = accuracy*100\n",
        "    print('Accuracy: %.2f%%' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epochs: 10 \t Batch Size: 16\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Accuracy: 70.39%\n",
            "Epochs: 20 \t Batch Size: 16\n",
            "Accuracy: 70.27%\n",
            "Epochs: 30 \t Batch Size: 16\n",
            "Accuracy: 70.59%\n",
            "Epochs: 40 \t Batch Size: 16\n",
            "Accuracy: 70.60%\n",
            "Epochs: 50 \t Batch Size: 16\n",
            "Accuracy: 70.44%\n",
            "Epochs: 60 \t Batch Size: 16\n",
            "Accuracy: 70.70%\n",
            "Epochs: 70 \t Batch Size: 16\n",
            "Accuracy: 70.38%\n",
            "Epochs: 80 \t Batch Size: 16\n",
            "Accuracy: 70.79%\n",
            "Epochs: 90 \t Batch Size: 16\n",
            "Accuracy: 70.85%\n",
            "Epochs: 100 \t Batch Size: 16\n",
            "Accuracy: 70.80%\n",
            "Epochs: 110 \t Batch Size: 16\n",
            "Accuracy: 70.66%\n",
            "Epochs: 120 \t Batch Size: 16\n",
            "Accuracy: 70.85%\n",
            "Epochs: 130 \t Batch Size: 16\n",
            "Accuracy: 70.72%\n",
            "Epochs: 140 \t Batch Size: 16\n",
            "Accuracy: 70.70%\n",
            "Epochs: 10 \t Batch Size: 32\n",
            "Accuracy: 70.41%\n",
            "Epochs: 20 \t Batch Size: 32\n",
            "Accuracy: 70.28%\n",
            "Epochs: 30 \t Batch Size: 32\n",
            "Accuracy: 70.56%\n",
            "Epochs: 40 \t Batch Size: 32\n",
            "Accuracy: 70.51%\n",
            "Epochs: 50 \t Batch Size: 32\n",
            "Accuracy: 70.69%\n",
            "Epochs: 60 \t Batch Size: 32\n",
            "Accuracy: 70.75%\n",
            "Epochs: 70 \t Batch Size: 32\n",
            "Accuracy: 70.74%\n",
            "Epochs: 80 \t Batch Size: 32\n",
            "Accuracy: 70.78%\n",
            "Epochs: 90 \t Batch Size: 32\n",
            "Accuracy: 70.76%\n",
            "Epochs: 100 \t Batch Size: 32\n",
            "Accuracy: 70.73%\n",
            "Epochs: 110 \t Batch Size: 32\n",
            "Accuracy: 70.74%\n",
            "Epochs: 120 \t Batch Size: 32\n",
            "Accuracy: 70.78%\n",
            "Epochs: 130 \t Batch Size: 32\n",
            "Accuracy: 70.62%\n",
            "Epochs: 140 \t Batch Size: 32\n",
            "Accuracy: 70.75%\n",
            "Epochs: 10 \t Batch Size: 48\n",
            "Accuracy: 70.37%\n",
            "Epochs: 20 \t Batch Size: 48\n",
            "Accuracy: 70.40%\n",
            "Epochs: 30 \t Batch Size: 48\n",
            "Accuracy: 70.52%\n",
            "Epochs: 40 \t Batch Size: 48\n",
            "Accuracy: 70.59%\n",
            "Epochs: 50 \t Batch Size: 48\n",
            "Accuracy: 70.52%\n",
            "Epochs: 60 \t Batch Size: 48\n",
            "Accuracy: 70.72%\n",
            "Epochs: 70 \t Batch Size: 48\n",
            "Accuracy: 70.80%\n",
            "Epochs: 80 \t Batch Size: 48\n",
            "Accuracy: 70.76%\n",
            "Epochs: 90 \t Batch Size: 48\n",
            "Accuracy: 70.77%\n",
            "Epochs: 100 \t Batch Size: 48\n",
            "Accuracy: 70.72%\n",
            "Epochs: 110 \t Batch Size: 48\n",
            "Accuracy: 70.85%\n",
            "Epochs: 120 \t Batch Size: 48\n",
            "Accuracy: 70.65%\n",
            "Epochs: 130 \t Batch Size: 48\n",
            "Accuracy: 70.63%\n",
            "Epochs: 140 \t Batch Size: 48\n",
            "Accuracy: 70.79%\n",
            "Epochs: 10 \t Batch Size: 64\n",
            "Accuracy: 70.35%\n",
            "Epochs: 20 \t Batch Size: 64\n",
            "Accuracy: 70.44%\n",
            "Epochs: 30 \t Batch Size: 64\n",
            "Accuracy: 70.47%\n",
            "Epochs: 40 \t Batch Size: 64\n",
            "Accuracy: 70.66%\n",
            "Epochs: 50 \t Batch Size: 64\n",
            "Accuracy: 70.62%\n",
            "Epochs: 60 \t Batch Size: 64\n",
            "Accuracy: 70.78%\n",
            "Epochs: 70 \t Batch Size: 64\n",
            "Accuracy: 70.55%\n",
            "Epochs: 80 \t Batch Size: 64\n",
            "Accuracy: 70.78%\n",
            "Epochs: 90 \t Batch Size: 64\n",
            "Accuracy: 70.78%\n",
            "Epochs: 100 \t Batch Size: 64\n",
            "Accuracy: 70.76%\n",
            "Epochs: 110 \t Batch Size: 64\n",
            "Accuracy: 70.59%\n",
            "Epochs: 120 \t Batch Size: 64\n",
            "Accuracy: 70.76%\n",
            "Epochs: 130 \t Batch Size: 64\n",
            "Accuracy: 70.70%\n",
            "Epochs: 140 \t Batch Size: 64\n",
            "Accuracy: 70.74%\n",
            "Epochs: 10 \t Batch Size: 80\n",
            "Accuracy: 70.30%\n",
            "Epochs: 20 \t Batch Size: 80\n",
            "Accuracy: 70.45%\n",
            "Epochs: 30 \t Batch Size: 80\n",
            "Accuracy: 70.51%\n",
            "Epochs: 40 \t Batch Size: 80\n",
            "Accuracy: 70.67%\n",
            "Epochs: 50 \t Batch Size: 80\n",
            "Accuracy: 70.47%\n",
            "Epochs: 60 \t Batch Size: 80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6s5lRjRMS9x"
      },
      "source": [
        "# Hyperparameters\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9idUNc9rPBGR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5873a71d-52ed-4603-8c47-a036f08fa412"
      },
      "source": [
        "!pip install git+https://github.com/keras-team/keras-tuner\n",
        "# !pip uninstall tensorflow -y\n",
        "!pip install tensorflow-gpu\n",
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/keras-team/keras-tuner\n",
            "  Cloning https://github.com/keras-team/keras-tuner to /tmp/pip-req-build-dbblphoy\n",
            "  Running command git clone -q https://github.com/keras-team/keras-tuner /tmp/pip-req-build-dbblphoy\n",
            "Requirement already satisfied (use --upgrade to upgrade): keras-tuner==1.0.3 from git+https://github.com/keras-team/keras-tuner in /usr/local/lib/python3.7/dist-packages\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (20.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (1.4.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (2.4.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.3) (5.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner==1.0.3) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.3) (1.24.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.4.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.36.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (0.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (54.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.3) (1.32.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (5.0.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.3) (0.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.3) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.7.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (0.2.8)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->keras-tuner==1.0.3) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->keras-tuner==1.0.3) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.3) (0.2.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.3) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->keras-tuner==1.0.3) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->keras-tuner==1.0.3) (0.4.8)\n",
            "Building wheels for collected packages: keras-tuner\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.3-cp37-none-any.whl size=93604 sha256=91d27f0aa114968deee6dce7e40b81365f98a8d465db62472f57a3bc743cbab0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-s55ow8p_/wheels/6c/55/2d/6e178386cb7a2d7da5a7059752a2b58791705c9c8718c5f07a\n",
            "Successfully built keras-tuner\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/cc/a27e73cf8b23f2ce4bdd2b7089a42a7819ce6dd7366dceba406ddc5daa9c/tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     || 394.3MB 31kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.27.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (54.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gdown) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gexxJyOsPFp3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pprint import pprint\n",
        "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format='retina'\n",
        "\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
        "\n",
        "rcParams['figure.figsize'] = 16, 10\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "np.random.seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c55HC7mHMF_o"
      },
      "source": [
        "def tune_optimizer_model(hp):\n",
        "    model = keras.Sequential()\n",
        "\n",
        "    model.add(keras.layers.Dense(24, input_dim=5,kernel_initializer='random_uniform'))\n",
        "\n",
        "    model.add(keras.layers.Dense(64,activation=\"relu\",kernel_initializer='random_uniform'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Dropout(.5))\n",
        "    model.add(keras.layers.Dense(64, activation=\"relu\",kernel_initializer='random_uniform'))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(keras.layers.Dense(1,activation=\"sigmoid\",kernel_initializer='random_uniform'))\n",
        "    optimizer = hp.Choice('optimizer', ['adam', 'sgd', 'rmsprop'])\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss = 'binary_crossentropy',\n",
        "        metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlwpO-hLOwVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab31ef3-9795-4a5c-894f-c982907d9818"
      },
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "MAX_TRIALS = 20\n",
        "EXECUTIONS_PER_TRIAL = 5\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    tune_optimizer_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=MAX_TRIALS,\n",
        "    executions_per_trial=EXECUTIONS_PER_TRIAL,\n",
        "    directory='test_dir',\n",
        "    project_name='tune_optimizer',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "tuner.search_space_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project test_dir/tune_optimizer/oracle.json\n",
            "Search space summary\n",
            "Default search space size: 1\n",
            "optimizer (Choice)\n",
            "{'default': 'adam', 'conditions': [], 'values': ['adam', 'sgd', 'rmsprop'], 'ordered': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oTPV-dVMeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3698162-870e-4c15-9dd0-632c7c05a4f0"
      },
      "source": [
        "TRAIN_EPOCHS = 20\n",
        "\n",
        "tuner.search(x=x_train,\n",
        "             y=y_train,\n",
        "             epochs=TRAIN_EPOCHS,\n",
        "             validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 3 Complete [00h 09m 51s]\n",
            "val_accuracy: 0.7029742956161499\n",
            "\n",
            "Best val_accuracy So Far: 0.7031591296195984\n",
            "Total elapsed time: 00h 31m 44s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdB9VQvaRXyM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcd5e1d1-7b4e-4a84-aac5-2da5a0a87d55"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in test_dir/tune_optimizer\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "optimizer: rmsprop\n",
            "Score: 0.7031591296195984\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "optimizer: adam\n",
            "Score: 0.7030419826507568\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "optimizer: sgd\n",
            "Score: 0.7029742956161499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmiqVb1kRZgr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c6962e-b193-4e97-fb7a-76c4f1ca0022"
      },
      "source": [
        "tuner.oracle.get_best_trials(num_trials=1)[0].hyperparameters.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'optimizer': 'rmsprop'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljbJqKM2Mt94"
      },
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCJIIFxrRac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a1f66dc-1e10-4a9d-d179-aef4eed92bb6"
      },
      "source": [
        "best_model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 24)                144       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                1600      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 6,481\n",
            "Trainable params: 6,225\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGVIkca1Mx9N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}